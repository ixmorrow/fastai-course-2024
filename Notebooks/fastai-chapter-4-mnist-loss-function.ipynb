{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -Uqq fastai","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:19:22.794569Z","iopub.execute_input":"2024-02-18T01:19:22.795786Z","iopub.status.idle":"2024-02-18T01:19:42.073009Z","shell.execute_reply.started":"2024-02-18T01:19:22.795729Z","shell.execute_reply":"2024-02-18T01:19:42.071405Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#hide\nfrom fastai.vision.all import *\n\nmatplotlib.rc('image', cmap='Greys')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-18T01:20:31.703885Z","iopub.execute_input":"2024-02-18T01:20:31.704579Z","iopub.status.idle":"2024-02-18T01:20:31.721402Z","shell.execute_reply.started":"2024-02-18T01:20:31.704512Z","shell.execute_reply":"2024-02-18T01:20:31.719148Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# import mnist dataset from fastai\npath = untar_data(URLs.MNIST_SAMPLE)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:20:34.856414Z","iopub.execute_input":"2024-02-18T01:20:34.857093Z","iopub.status.idle":"2024-02-18T01:20:41.211339Z","shell.execute_reply.started":"2024-02-18T01:20:34.857056Z","shell.execute_reply":"2024-02-18T01:20:41.209833Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.14% [3219456/3214948 00:01&lt;00:00]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"#hide\nPath.BASE_PATH = path","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:20:44.662581Z","iopub.execute_input":"2024-02-18T01:20:44.663104Z","iopub.status.idle":"2024-02-18T01:20:44.668669Z","shell.execute_reply.started":"2024-02-18T01:20:44.663059Z","shell.execute_reply":"2024-02-18T01:20:44.667642Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"View training data","metadata":{}},{"cell_type":"code","source":"path.ls()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:20:56.813055Z","iopub.execute_input":"2024-02-18T01:20:56.813585Z","iopub.status.idle":"2024-02-18T01:20:56.822838Z","shell.execute_reply.started":"2024-02-18T01:20:56.813537Z","shell.execute_reply":"2024-02-18T01:20:56.821639Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(#3) [Path('valid'),Path('labels.csv'),Path('train')]"},"metadata":{}}]},{"cell_type":"markdown","source":"There's a folder of 3s, and a folder of 7s. In machine learning parlance, we say that \"3\" and \"7\" are the labels (or targets) in this dataset. Let's take a look in one of these folders (using sorted to ensure we all get the same order of files):","metadata":{}},{"cell_type":"code","source":"threes = (path/'train'/'3').ls().sorted()\nsevens = (path/'train'/'7').ls().sorted()\nthrees","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:21:35.490986Z","iopub.execute_input":"2024-02-18T01:21:35.491485Z","iopub.status.idle":"2024-02-18T01:21:35.676303Z","shell.execute_reply.started":"2024-02-18T01:21:35.491449Z","shell.execute_reply":"2024-02-18T01:21:35.675418Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"},"metadata":{}}]},{"cell_type":"code","source":"im3_path = threes[1]\nim3 = Image.open(im3_path)\nim3","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:21:45.242123Z","iopub.execute_input":"2024-02-18T01:21:45.242600Z","iopub.status.idle":"2024-02-18T01:21:45.266039Z","shell.execute_reply.started":"2024-02-18T01:21:45.242564Z","shell.execute_reply":"2024-02-18T01:21:45.264570Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":"#hide_output\nim3_t = tensor(im3)\ndf = pd.DataFrame(im3_t[4:15,4:22])\ndf.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:22:01.757139Z","iopub.execute_input":"2024-02-18T01:22:01.758647Z","iopub.status.idle":"2024-02-18T01:22:02.363399Z","shell.execute_reply.started":"2024-02-18T01:22:01.758588Z","shell.execute_reply":"2024-02-18T01:22:02.362389Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7b6599d4cc70>","text/html":"<style type=\"text/css\">\n#T_320ad_row0_col0, #T_320ad_row0_col1, #T_320ad_row0_col2, #T_320ad_row0_col3, #T_320ad_row0_col4, #T_320ad_row0_col5, #T_320ad_row0_col6, #T_320ad_row0_col7, #T_320ad_row0_col8, #T_320ad_row0_col9, #T_320ad_row0_col10, #T_320ad_row0_col11, #T_320ad_row0_col12, #T_320ad_row0_col13, #T_320ad_row0_col14, #T_320ad_row0_col15, #T_320ad_row0_col16, #T_320ad_row0_col17, #T_320ad_row1_col0, #T_320ad_row1_col1, #T_320ad_row1_col2, #T_320ad_row1_col3, #T_320ad_row1_col4, #T_320ad_row1_col15, #T_320ad_row1_col16, #T_320ad_row1_col17, #T_320ad_row2_col0, #T_320ad_row2_col1, #T_320ad_row2_col2, #T_320ad_row2_col15, #T_320ad_row2_col16, #T_320ad_row2_col17, #T_320ad_row3_col0, #T_320ad_row3_col15, #T_320ad_row3_col16, #T_320ad_row3_col17, #T_320ad_row4_col0, #T_320ad_row4_col6, #T_320ad_row4_col7, #T_320ad_row4_col8, #T_320ad_row4_col9, #T_320ad_row4_col10, #T_320ad_row4_col15, #T_320ad_row4_col16, #T_320ad_row4_col17, #T_320ad_row5_col0, #T_320ad_row5_col5, #T_320ad_row5_col6, #T_320ad_row5_col7, #T_320ad_row5_col8, #T_320ad_row5_col9, #T_320ad_row5_col15, #T_320ad_row5_col16, #T_320ad_row5_col17, #T_320ad_row6_col0, #T_320ad_row6_col1, #T_320ad_row6_col2, #T_320ad_row6_col3, #T_320ad_row6_col4, #T_320ad_row6_col5, #T_320ad_row6_col6, #T_320ad_row6_col7, #T_320ad_row6_col8, #T_320ad_row6_col9, #T_320ad_row6_col14, #T_320ad_row6_col15, #T_320ad_row6_col16, #T_320ad_row6_col17, #T_320ad_row7_col0, #T_320ad_row7_col1, #T_320ad_row7_col2, #T_320ad_row7_col3, #T_320ad_row7_col4, #T_320ad_row7_col5, #T_320ad_row7_col6, #T_320ad_row7_col13, #T_320ad_row7_col14, #T_320ad_row7_col15, #T_320ad_row7_col16, #T_320ad_row7_col17, #T_320ad_row8_col0, #T_320ad_row8_col1, #T_320ad_row8_col2, #T_320ad_row8_col3, #T_320ad_row8_col4, #T_320ad_row8_col13, #T_320ad_row8_col14, #T_320ad_row8_col15, #T_320ad_row8_col16, #T_320ad_row8_col17, #T_320ad_row9_col0, #T_320ad_row9_col1, #T_320ad_row9_col2, #T_320ad_row9_col3, #T_320ad_row9_col4, #T_320ad_row9_col16, #T_320ad_row9_col17, #T_320ad_row10_col0, #T_320ad_row10_col1, #T_320ad_row10_col2, #T_320ad_row10_col3, #T_320ad_row10_col4, #T_320ad_row10_col5, #T_320ad_row10_col6, #T_320ad_row10_col17 {\n  font-size: 6pt;\n  background-color: #ffffff;\n  color: #000000;\n}\n#T_320ad_row1_col5 {\n  font-size: 6pt;\n  background-color: #efefef;\n  color: #000000;\n}\n#T_320ad_row1_col6, #T_320ad_row1_col13 {\n  font-size: 6pt;\n  background-color: #7c7c7c;\n  color: #f1f1f1;\n}\n#T_320ad_row1_col7 {\n  font-size: 6pt;\n  background-color: #4a4a4a;\n  color: #f1f1f1;\n}\n#T_320ad_row1_col8, #T_320ad_row1_col9, #T_320ad_row1_col10, #T_320ad_row2_col5, #T_320ad_row2_col6, #T_320ad_row2_col7, #T_320ad_row2_col11, #T_320ad_row2_col12, #T_320ad_row2_col13, #T_320ad_row3_col4, #T_320ad_row3_col12, #T_320ad_row3_col13, #T_320ad_row4_col1, #T_320ad_row4_col2, #T_320ad_row4_col3, #T_320ad_row4_col12, #T_320ad_row4_col13, #T_320ad_row5_col12, #T_320ad_row6_col11, #T_320ad_row9_col11, #T_320ad_row10_col11, #T_320ad_row10_col12, #T_320ad_row10_col13, #T_320ad_row10_col14, #T_320ad_row10_col15, #T_320ad_row10_col16 {\n  font-size: 6pt;\n  background-color: #000000;\n  color: #f1f1f1;\n}\n#T_320ad_row1_col11 {\n  font-size: 6pt;\n  background-color: #606060;\n  color: #f1f1f1;\n}\n#T_320ad_row1_col12 {\n  font-size: 6pt;\n  background-color: #4d4d4d;\n  color: #f1f1f1;\n}\n#T_320ad_row1_col14 {\n  font-size: 6pt;\n  background-color: #bbbbbb;\n  color: #000000;\n}\n#T_320ad_row2_col3 {\n  font-size: 6pt;\n  background-color: #e4e4e4;\n  color: #000000;\n}\n#T_320ad_row2_col4, #T_320ad_row8_col6 {\n  font-size: 6pt;\n  background-color: #6b6b6b;\n  color: #f1f1f1;\n}\n#T_320ad_row2_col8, #T_320ad_row2_col14, #T_320ad_row3_col14 {\n  font-size: 6pt;\n  background-color: #171717;\n  color: #f1f1f1;\n}\n#T_320ad_row2_col9, #T_320ad_row3_col11 {\n  font-size: 6pt;\n  background-color: #4b4b4b;\n  color: #f1f1f1;\n}\n#T_320ad_row2_col10, #T_320ad_row7_col10, #T_320ad_row8_col8, #T_320ad_row8_col10, #T_320ad_row9_col8, #T_320ad_row9_col10 {\n  font-size: 6pt;\n  background-color: #010101;\n  color: #f1f1f1;\n}\n#T_320ad_row3_col1 {\n  font-size: 6pt;\n  background-color: #272727;\n  color: #f1f1f1;\n}\n#T_320ad_row3_col2 {\n  font-size: 6pt;\n  background-color: #0a0a0a;\n  color: #f1f1f1;\n}\n#T_320ad_row3_col3 {\n  font-size: 6pt;\n  background-color: #050505;\n  color: #f1f1f1;\n}\n#T_320ad_row3_col5 {\n  font-size: 6pt;\n  background-color: #333333;\n  color: #f1f1f1;\n}\n#T_320ad_row3_col6 {\n  font-size: 6pt;\n  background-color: #e6e6e6;\n  color: #000000;\n}\n#T_320ad_row3_col7, #T_320ad_row3_col10 {\n  font-size: 6pt;\n  background-color: #fafafa;\n  color: #000000;\n}\n#T_320ad_row3_col8 {\n  font-size: 6pt;\n  background-color: #fbfbfb;\n  color: #000000;\n}\n#T_320ad_row3_col9 {\n  font-size: 6pt;\n  background-color: #fdfdfd;\n  color: #000000;\n}\n#T_320ad_row4_col4 {\n  font-size: 6pt;\n  background-color: #1b1b1b;\n  color: #f1f1f1;\n}\n#T_320ad_row4_col5 {\n  font-size: 6pt;\n  background-color: #e0e0e0;\n  color: #000000;\n}\n#T_320ad_row4_col11 {\n  font-size: 6pt;\n  background-color: #4e4e4e;\n  color: #f1f1f1;\n}\n#T_320ad_row4_col14 {\n  font-size: 6pt;\n  background-color: #767676;\n  color: #f1f1f1;\n}\n#T_320ad_row5_col1 {\n  font-size: 6pt;\n  background-color: #fcfcfc;\n  color: #000000;\n}\n#T_320ad_row5_col2, #T_320ad_row5_col3 {\n  font-size: 6pt;\n  background-color: #f6f6f6;\n  color: #000000;\n}\n#T_320ad_row5_col4, #T_320ad_row7_col7 {\n  font-size: 6pt;\n  background-color: #f8f8f8;\n  color: #000000;\n}\n#T_320ad_row5_col10, #T_320ad_row10_col7 {\n  font-size: 6pt;\n  background-color: #e8e8e8;\n  color: #000000;\n}\n#T_320ad_row5_col11 {\n  font-size: 6pt;\n  background-color: #222222;\n  color: #f1f1f1;\n}\n#T_320ad_row5_col13, #T_320ad_row6_col12 {\n  font-size: 6pt;\n  background-color: #090909;\n  color: #f1f1f1;\n}\n#T_320ad_row5_col14 {\n  font-size: 6pt;\n  background-color: #d0d0d0;\n  color: #000000;\n}\n#T_320ad_row6_col10, #T_320ad_row7_col11, #T_320ad_row9_col6 {\n  font-size: 6pt;\n  background-color: #060606;\n  color: #f1f1f1;\n}\n#T_320ad_row6_col13 {\n  font-size: 6pt;\n  background-color: #979797;\n  color: #f1f1f1;\n}\n#T_320ad_row7_col8 {\n  font-size: 6pt;\n  background-color: #b6b6b6;\n  color: #000000;\n}\n#T_320ad_row7_col9 {\n  font-size: 6pt;\n  background-color: #252525;\n  color: #f1f1f1;\n}\n#T_320ad_row7_col12 {\n  font-size: 6pt;\n  background-color: #999999;\n  color: #f1f1f1;\n}\n#T_320ad_row8_col5 {\n  font-size: 6pt;\n  background-color: #f9f9f9;\n  color: #000000;\n}\n#T_320ad_row8_col7 {\n  font-size: 6pt;\n  background-color: #101010;\n  color: #f1f1f1;\n}\n#T_320ad_row8_col9, #T_320ad_row9_col9 {\n  font-size: 6pt;\n  background-color: #020202;\n  color: #f1f1f1;\n}\n#T_320ad_row8_col11 {\n  font-size: 6pt;\n  background-color: #545454;\n  color: #f1f1f1;\n}\n#T_320ad_row8_col12 {\n  font-size: 6pt;\n  background-color: #f1f1f1;\n  color: #000000;\n}\n#T_320ad_row9_col5 {\n  font-size: 6pt;\n  background-color: #f7f7f7;\n  color: #000000;\n}\n#T_320ad_row9_col7 {\n  font-size: 6pt;\n  background-color: #030303;\n  color: #f1f1f1;\n}\n#T_320ad_row9_col12 {\n  font-size: 6pt;\n  background-color: #181818;\n  color: #f1f1f1;\n}\n#T_320ad_row9_col13 {\n  font-size: 6pt;\n  background-color: #303030;\n  color: #f1f1f1;\n}\n#T_320ad_row9_col14 {\n  font-size: 6pt;\n  background-color: #a9a9a9;\n  color: #f1f1f1;\n}\n#T_320ad_row9_col15 {\n  font-size: 6pt;\n  background-color: #fefefe;\n  color: #000000;\n}\n#T_320ad_row10_col8, #T_320ad_row10_col9 {\n  font-size: 6pt;\n  background-color: #bababa;\n  color: #000000;\n}\n#T_320ad_row10_col10 {\n  font-size: 6pt;\n  background-color: #393939;\n  color: #f1f1f1;\n}\n</style>\n<table id=\"T_320ad\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_320ad_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n      <th id=\"T_320ad_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n      <th id=\"T_320ad_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n      <th id=\"T_320ad_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n      <th id=\"T_320ad_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n      <th id=\"T_320ad_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n      <th id=\"T_320ad_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n      <th id=\"T_320ad_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n      <th id=\"T_320ad_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n      <th id=\"T_320ad_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n      <th id=\"T_320ad_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n      <th id=\"T_320ad_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n      <th id=\"T_320ad_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n      <th id=\"T_320ad_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n      <th id=\"T_320ad_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n      <th id=\"T_320ad_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n      <th id=\"T_320ad_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n      <th id=\"T_320ad_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_320ad_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_320ad_row0_col0\" class=\"data row0 col0\" >0</td>\n      <td id=\"T_320ad_row0_col1\" class=\"data row0 col1\" >0</td>\n      <td id=\"T_320ad_row0_col2\" class=\"data row0 col2\" >0</td>\n      <td id=\"T_320ad_row0_col3\" class=\"data row0 col3\" >0</td>\n      <td id=\"T_320ad_row0_col4\" class=\"data row0 col4\" >0</td>\n      <td id=\"T_320ad_row0_col5\" class=\"data row0 col5\" >0</td>\n      <td id=\"T_320ad_row0_col6\" class=\"data row0 col6\" >0</td>\n      <td id=\"T_320ad_row0_col7\" class=\"data row0 col7\" >0</td>\n      <td id=\"T_320ad_row0_col8\" class=\"data row0 col8\" >0</td>\n      <td id=\"T_320ad_row0_col9\" class=\"data row0 col9\" >0</td>\n      <td id=\"T_320ad_row0_col10\" class=\"data row0 col10\" >0</td>\n      <td id=\"T_320ad_row0_col11\" class=\"data row0 col11\" >0</td>\n      <td id=\"T_320ad_row0_col12\" class=\"data row0 col12\" >0</td>\n      <td id=\"T_320ad_row0_col13\" class=\"data row0 col13\" >0</td>\n      <td id=\"T_320ad_row0_col14\" class=\"data row0 col14\" >0</td>\n      <td id=\"T_320ad_row0_col15\" class=\"data row0 col15\" >0</td>\n      <td id=\"T_320ad_row0_col16\" class=\"data row0 col16\" >0</td>\n      <td id=\"T_320ad_row0_col17\" class=\"data row0 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_320ad_row1_col0\" class=\"data row1 col0\" >0</td>\n      <td id=\"T_320ad_row1_col1\" class=\"data row1 col1\" >0</td>\n      <td id=\"T_320ad_row1_col2\" class=\"data row1 col2\" >0</td>\n      <td id=\"T_320ad_row1_col3\" class=\"data row1 col3\" >0</td>\n      <td id=\"T_320ad_row1_col4\" class=\"data row1 col4\" >0</td>\n      <td id=\"T_320ad_row1_col5\" class=\"data row1 col5\" >29</td>\n      <td id=\"T_320ad_row1_col6\" class=\"data row1 col6\" >150</td>\n      <td id=\"T_320ad_row1_col7\" class=\"data row1 col7\" >195</td>\n      <td id=\"T_320ad_row1_col8\" class=\"data row1 col8\" >254</td>\n      <td id=\"T_320ad_row1_col9\" class=\"data row1 col9\" >255</td>\n      <td id=\"T_320ad_row1_col10\" class=\"data row1 col10\" >254</td>\n      <td id=\"T_320ad_row1_col11\" class=\"data row1 col11\" >176</td>\n      <td id=\"T_320ad_row1_col12\" class=\"data row1 col12\" >193</td>\n      <td id=\"T_320ad_row1_col13\" class=\"data row1 col13\" >150</td>\n      <td id=\"T_320ad_row1_col14\" class=\"data row1 col14\" >96</td>\n      <td id=\"T_320ad_row1_col15\" class=\"data row1 col15\" >0</td>\n      <td id=\"T_320ad_row1_col16\" class=\"data row1 col16\" >0</td>\n      <td id=\"T_320ad_row1_col17\" class=\"data row1 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_320ad_row2_col0\" class=\"data row2 col0\" >0</td>\n      <td id=\"T_320ad_row2_col1\" class=\"data row2 col1\" >0</td>\n      <td id=\"T_320ad_row2_col2\" class=\"data row2 col2\" >0</td>\n      <td id=\"T_320ad_row2_col3\" class=\"data row2 col3\" >48</td>\n      <td id=\"T_320ad_row2_col4\" class=\"data row2 col4\" >166</td>\n      <td id=\"T_320ad_row2_col5\" class=\"data row2 col5\" >224</td>\n      <td id=\"T_320ad_row2_col6\" class=\"data row2 col6\" >253</td>\n      <td id=\"T_320ad_row2_col7\" class=\"data row2 col7\" >253</td>\n      <td id=\"T_320ad_row2_col8\" class=\"data row2 col8\" >234</td>\n      <td id=\"T_320ad_row2_col9\" class=\"data row2 col9\" >196</td>\n      <td id=\"T_320ad_row2_col10\" class=\"data row2 col10\" >253</td>\n      <td id=\"T_320ad_row2_col11\" class=\"data row2 col11\" >253</td>\n      <td id=\"T_320ad_row2_col12\" class=\"data row2 col12\" >253</td>\n      <td id=\"T_320ad_row2_col13\" class=\"data row2 col13\" >253</td>\n      <td id=\"T_320ad_row2_col14\" class=\"data row2 col14\" >233</td>\n      <td id=\"T_320ad_row2_col15\" class=\"data row2 col15\" >0</td>\n      <td id=\"T_320ad_row2_col16\" class=\"data row2 col16\" >0</td>\n      <td id=\"T_320ad_row2_col17\" class=\"data row2 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_320ad_row3_col0\" class=\"data row3 col0\" >0</td>\n      <td id=\"T_320ad_row3_col1\" class=\"data row3 col1\" >93</td>\n      <td id=\"T_320ad_row3_col2\" class=\"data row3 col2\" >244</td>\n      <td id=\"T_320ad_row3_col3\" class=\"data row3 col3\" >249</td>\n      <td id=\"T_320ad_row3_col4\" class=\"data row3 col4\" >253</td>\n      <td id=\"T_320ad_row3_col5\" class=\"data row3 col5\" >187</td>\n      <td id=\"T_320ad_row3_col6\" class=\"data row3 col6\" >46</td>\n      <td id=\"T_320ad_row3_col7\" class=\"data row3 col7\" >10</td>\n      <td id=\"T_320ad_row3_col8\" class=\"data row3 col8\" >8</td>\n      <td id=\"T_320ad_row3_col9\" class=\"data row3 col9\" >4</td>\n      <td id=\"T_320ad_row3_col10\" class=\"data row3 col10\" >10</td>\n      <td id=\"T_320ad_row3_col11\" class=\"data row3 col11\" >194</td>\n      <td id=\"T_320ad_row3_col12\" class=\"data row3 col12\" >253</td>\n      <td id=\"T_320ad_row3_col13\" class=\"data row3 col13\" >253</td>\n      <td id=\"T_320ad_row3_col14\" class=\"data row3 col14\" >233</td>\n      <td id=\"T_320ad_row3_col15\" class=\"data row3 col15\" >0</td>\n      <td id=\"T_320ad_row3_col16\" class=\"data row3 col16\" >0</td>\n      <td id=\"T_320ad_row3_col17\" class=\"data row3 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_320ad_row4_col0\" class=\"data row4 col0\" >0</td>\n      <td id=\"T_320ad_row4_col1\" class=\"data row4 col1\" >107</td>\n      <td id=\"T_320ad_row4_col2\" class=\"data row4 col2\" >253</td>\n      <td id=\"T_320ad_row4_col3\" class=\"data row4 col3\" >253</td>\n      <td id=\"T_320ad_row4_col4\" class=\"data row4 col4\" >230</td>\n      <td id=\"T_320ad_row4_col5\" class=\"data row4 col5\" >48</td>\n      <td id=\"T_320ad_row4_col6\" class=\"data row4 col6\" >0</td>\n      <td id=\"T_320ad_row4_col7\" class=\"data row4 col7\" >0</td>\n      <td id=\"T_320ad_row4_col8\" class=\"data row4 col8\" >0</td>\n      <td id=\"T_320ad_row4_col9\" class=\"data row4 col9\" >0</td>\n      <td id=\"T_320ad_row4_col10\" class=\"data row4 col10\" >0</td>\n      <td id=\"T_320ad_row4_col11\" class=\"data row4 col11\" >192</td>\n      <td id=\"T_320ad_row4_col12\" class=\"data row4 col12\" >253</td>\n      <td id=\"T_320ad_row4_col13\" class=\"data row4 col13\" >253</td>\n      <td id=\"T_320ad_row4_col14\" class=\"data row4 col14\" >156</td>\n      <td id=\"T_320ad_row4_col15\" class=\"data row4 col15\" >0</td>\n      <td id=\"T_320ad_row4_col16\" class=\"data row4 col16\" >0</td>\n      <td id=\"T_320ad_row4_col17\" class=\"data row4 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_320ad_row5_col0\" class=\"data row5 col0\" >0</td>\n      <td id=\"T_320ad_row5_col1\" class=\"data row5 col1\" >3</td>\n      <td id=\"T_320ad_row5_col2\" class=\"data row5 col2\" >20</td>\n      <td id=\"T_320ad_row5_col3\" class=\"data row5 col3\" >20</td>\n      <td id=\"T_320ad_row5_col4\" class=\"data row5 col4\" >15</td>\n      <td id=\"T_320ad_row5_col5\" class=\"data row5 col5\" >0</td>\n      <td id=\"T_320ad_row5_col6\" class=\"data row5 col6\" >0</td>\n      <td id=\"T_320ad_row5_col7\" class=\"data row5 col7\" >0</td>\n      <td id=\"T_320ad_row5_col8\" class=\"data row5 col8\" >0</td>\n      <td id=\"T_320ad_row5_col9\" class=\"data row5 col9\" >0</td>\n      <td id=\"T_320ad_row5_col10\" class=\"data row5 col10\" >43</td>\n      <td id=\"T_320ad_row5_col11\" class=\"data row5 col11\" >224</td>\n      <td id=\"T_320ad_row5_col12\" class=\"data row5 col12\" >253</td>\n      <td id=\"T_320ad_row5_col13\" class=\"data row5 col13\" >245</td>\n      <td id=\"T_320ad_row5_col14\" class=\"data row5 col14\" >74</td>\n      <td id=\"T_320ad_row5_col15\" class=\"data row5 col15\" >0</td>\n      <td id=\"T_320ad_row5_col16\" class=\"data row5 col16\" >0</td>\n      <td id=\"T_320ad_row5_col17\" class=\"data row5 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_320ad_row6_col0\" class=\"data row6 col0\" >0</td>\n      <td id=\"T_320ad_row6_col1\" class=\"data row6 col1\" >0</td>\n      <td id=\"T_320ad_row6_col2\" class=\"data row6 col2\" >0</td>\n      <td id=\"T_320ad_row6_col3\" class=\"data row6 col3\" >0</td>\n      <td id=\"T_320ad_row6_col4\" class=\"data row6 col4\" >0</td>\n      <td id=\"T_320ad_row6_col5\" class=\"data row6 col5\" >0</td>\n      <td id=\"T_320ad_row6_col6\" class=\"data row6 col6\" >0</td>\n      <td id=\"T_320ad_row6_col7\" class=\"data row6 col7\" >0</td>\n      <td id=\"T_320ad_row6_col8\" class=\"data row6 col8\" >0</td>\n      <td id=\"T_320ad_row6_col9\" class=\"data row6 col9\" >0</td>\n      <td id=\"T_320ad_row6_col10\" class=\"data row6 col10\" >249</td>\n      <td id=\"T_320ad_row6_col11\" class=\"data row6 col11\" >253</td>\n      <td id=\"T_320ad_row6_col12\" class=\"data row6 col12\" >245</td>\n      <td id=\"T_320ad_row6_col13\" class=\"data row6 col13\" >126</td>\n      <td id=\"T_320ad_row6_col14\" class=\"data row6 col14\" >0</td>\n      <td id=\"T_320ad_row6_col15\" class=\"data row6 col15\" >0</td>\n      <td id=\"T_320ad_row6_col16\" class=\"data row6 col16\" >0</td>\n      <td id=\"T_320ad_row6_col17\" class=\"data row6 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_320ad_row7_col0\" class=\"data row7 col0\" >0</td>\n      <td id=\"T_320ad_row7_col1\" class=\"data row7 col1\" >0</td>\n      <td id=\"T_320ad_row7_col2\" class=\"data row7 col2\" >0</td>\n      <td id=\"T_320ad_row7_col3\" class=\"data row7 col3\" >0</td>\n      <td id=\"T_320ad_row7_col4\" class=\"data row7 col4\" >0</td>\n      <td id=\"T_320ad_row7_col5\" class=\"data row7 col5\" >0</td>\n      <td id=\"T_320ad_row7_col6\" class=\"data row7 col6\" >0</td>\n      <td id=\"T_320ad_row7_col7\" class=\"data row7 col7\" >14</td>\n      <td id=\"T_320ad_row7_col8\" class=\"data row7 col8\" >101</td>\n      <td id=\"T_320ad_row7_col9\" class=\"data row7 col9\" >223</td>\n      <td id=\"T_320ad_row7_col10\" class=\"data row7 col10\" >253</td>\n      <td id=\"T_320ad_row7_col11\" class=\"data row7 col11\" >248</td>\n      <td id=\"T_320ad_row7_col12\" class=\"data row7 col12\" >124</td>\n      <td id=\"T_320ad_row7_col13\" class=\"data row7 col13\" >0</td>\n      <td id=\"T_320ad_row7_col14\" class=\"data row7 col14\" >0</td>\n      <td id=\"T_320ad_row7_col15\" class=\"data row7 col15\" >0</td>\n      <td id=\"T_320ad_row7_col16\" class=\"data row7 col16\" >0</td>\n      <td id=\"T_320ad_row7_col17\" class=\"data row7 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_320ad_row8_col0\" class=\"data row8 col0\" >0</td>\n      <td id=\"T_320ad_row8_col1\" class=\"data row8 col1\" >0</td>\n      <td id=\"T_320ad_row8_col2\" class=\"data row8 col2\" >0</td>\n      <td id=\"T_320ad_row8_col3\" class=\"data row8 col3\" >0</td>\n      <td id=\"T_320ad_row8_col4\" class=\"data row8 col4\" >0</td>\n      <td id=\"T_320ad_row8_col5\" class=\"data row8 col5\" >11</td>\n      <td id=\"T_320ad_row8_col6\" class=\"data row8 col6\" >166</td>\n      <td id=\"T_320ad_row8_col7\" class=\"data row8 col7\" >239</td>\n      <td id=\"T_320ad_row8_col8\" class=\"data row8 col8\" >253</td>\n      <td id=\"T_320ad_row8_col9\" class=\"data row8 col9\" >253</td>\n      <td id=\"T_320ad_row8_col10\" class=\"data row8 col10\" >253</td>\n      <td id=\"T_320ad_row8_col11\" class=\"data row8 col11\" >187</td>\n      <td id=\"T_320ad_row8_col12\" class=\"data row8 col12\" >30</td>\n      <td id=\"T_320ad_row8_col13\" class=\"data row8 col13\" >0</td>\n      <td id=\"T_320ad_row8_col14\" class=\"data row8 col14\" >0</td>\n      <td id=\"T_320ad_row8_col15\" class=\"data row8 col15\" >0</td>\n      <td id=\"T_320ad_row8_col16\" class=\"data row8 col16\" >0</td>\n      <td id=\"T_320ad_row8_col17\" class=\"data row8 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_320ad_row9_col0\" class=\"data row9 col0\" >0</td>\n      <td id=\"T_320ad_row9_col1\" class=\"data row9 col1\" >0</td>\n      <td id=\"T_320ad_row9_col2\" class=\"data row9 col2\" >0</td>\n      <td id=\"T_320ad_row9_col3\" class=\"data row9 col3\" >0</td>\n      <td id=\"T_320ad_row9_col4\" class=\"data row9 col4\" >0</td>\n      <td id=\"T_320ad_row9_col5\" class=\"data row9 col5\" >16</td>\n      <td id=\"T_320ad_row9_col6\" class=\"data row9 col6\" >248</td>\n      <td id=\"T_320ad_row9_col7\" class=\"data row9 col7\" >250</td>\n      <td id=\"T_320ad_row9_col8\" class=\"data row9 col8\" >253</td>\n      <td id=\"T_320ad_row9_col9\" class=\"data row9 col9\" >253</td>\n      <td id=\"T_320ad_row9_col10\" class=\"data row9 col10\" >253</td>\n      <td id=\"T_320ad_row9_col11\" class=\"data row9 col11\" >253</td>\n      <td id=\"T_320ad_row9_col12\" class=\"data row9 col12\" >232</td>\n      <td id=\"T_320ad_row9_col13\" class=\"data row9 col13\" >213</td>\n      <td id=\"T_320ad_row9_col14\" class=\"data row9 col14\" >111</td>\n      <td id=\"T_320ad_row9_col15\" class=\"data row9 col15\" >2</td>\n      <td id=\"T_320ad_row9_col16\" class=\"data row9 col16\" >0</td>\n      <td id=\"T_320ad_row9_col17\" class=\"data row9 col17\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_320ad_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n      <td id=\"T_320ad_row10_col0\" class=\"data row10 col0\" >0</td>\n      <td id=\"T_320ad_row10_col1\" class=\"data row10 col1\" >0</td>\n      <td id=\"T_320ad_row10_col2\" class=\"data row10 col2\" >0</td>\n      <td id=\"T_320ad_row10_col3\" class=\"data row10 col3\" >0</td>\n      <td id=\"T_320ad_row10_col4\" class=\"data row10 col4\" >0</td>\n      <td id=\"T_320ad_row10_col5\" class=\"data row10 col5\" >0</td>\n      <td id=\"T_320ad_row10_col6\" class=\"data row10 col6\" >0</td>\n      <td id=\"T_320ad_row10_col7\" class=\"data row10 col7\" >43</td>\n      <td id=\"T_320ad_row10_col8\" class=\"data row10 col8\" >98</td>\n      <td id=\"T_320ad_row10_col9\" class=\"data row10 col9\" >98</td>\n      <td id=\"T_320ad_row10_col10\" class=\"data row10 col10\" >208</td>\n      <td id=\"T_320ad_row10_col11\" class=\"data row10 col11\" >253</td>\n      <td id=\"T_320ad_row10_col12\" class=\"data row10 col12\" >253</td>\n      <td id=\"T_320ad_row10_col13\" class=\"data row10 col13\" >253</td>\n      <td id=\"T_320ad_row10_col14\" class=\"data row10 col14\" >253</td>\n      <td id=\"T_320ad_row10_col15\" class=\"data row10 col15\" >187</td>\n      <td id=\"T_320ad_row10_col16\" class=\"data row10 col16\" >22</td>\n      <td id=\"T_320ad_row10_col17\" class=\"data row10 col17\" >0</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Create tensors out of the images using list comprehension!","metadata":{}},{"cell_type":"code","source":"seven_tensors = [tensor(Image.open(o)) for o in sevens]\nthree_tensors = [tensor(Image.open(o)) for o in threes]\nlen(three_tensors),len(seven_tensors)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:22:43.036644Z","iopub.execute_input":"2024-02-18T01:22:43.037386Z","iopub.status.idle":"2024-02-18T01:22:47.059291Z","shell.execute_reply.started":"2024-02-18T01:22:43.037325Z","shell.execute_reply":"2024-02-18T01:22:47.058055Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(6131, 6265)"},"metadata":{}}]},{"cell_type":"markdown","source":"Create tensors of the validation data as well:","metadata":{}},{"cell_type":"code","source":"valid_3_tens = torch.stack([tensor(Image.open(o)) \n                            for o in (path/'valid'/'3').ls()])\nvalid_3_tens = valid_3_tens.float()/255\nvalid_7_tens = torch.stack([tensor(Image.open(o)) \n                            for o in (path/'valid'/'7').ls()])\nvalid_7_tens = valid_7_tens.float()/255\nvalid_3_tens.shape,valid_7_tens.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:32:37.142972Z","iopub.execute_input":"2024-02-18T01:32:37.143568Z","iopub.status.idle":"2024-02-18T01:32:37.818011Z","shell.execute_reply.started":"2024-02-18T01:32:37.143504Z","shell.execute_reply":"2024-02-18T01:32:37.816748Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"},"metadata":{}}]},{"cell_type":"markdown","source":"Can use `show_image` function from Fast.ai to view a tensor of pixels as an image.","metadata":{}},{"cell_type":"code","source":"show_image(three_tensors[1]);","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:23:26.414431Z","iopub.execute_input":"2024-02-18T01:23:26.415411Z","iopub.status.idle":"2024-02-18T01:23:26.500387Z","shell.execute_reply.started":"2024-02-18T01:23:26.415326Z","shell.execute_reply":"2024-02-18T01:23:26.498761Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 100x100 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"For every pixel position, we want to compute the average over all the images of the intensity of that pixel. To do this we first combine all the images in this list into a single three-dimensional tensor. The most common way to describe such a tensor is to call it a rank-3 tensor. We often need to stack up individual tensors in a collection into a single tensor. Unsurprisingly, PyTorch comes with a function called stack that we can use for this purpose.\n\nSome operations in PyTorch, such as taking a mean, require us to cast our integer types to float types. Since we'll be needing this later, we'll also cast our stacked tensor to float now. Casting in PyTorch is as simple as typing the name of the type you wish to cast to, and treating it as a method.\n\nGenerally when images are floats, the pixel values are expected to be between 0 and 1, so we will also divide by 255 here:","metadata":{}},{"cell_type":"code","source":"stacked_sevens = torch.stack(seven_tensors).float()/255\nstacked_threes = torch.stack(three_tensors).float()/255\nstacked_threes.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:24:11.489096Z","iopub.execute_input":"2024-02-18T01:24:11.489626Z","iopub.status.idle":"2024-02-18T01:24:11.633468Z","shell.execute_reply.started":"2024-02-18T01:24:11.489585Z","shell.execute_reply":"2024-02-18T01:24:11.632329Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.Size([6131, 28, 28])"},"metadata":{}}]},{"cell_type":"markdown","source":"Perhaps the most important attribute of a tensor is its shape. This tells you the length of each axis. In this case, we can see that we have 6,131 images, each of size 28×28 pixels. There is nothing specifically about this tensor that says that the first axis is the number of images, the second is the height, and the third is the width—the semantics of a tensor are entirely up to us, and how we construct it. As far as PyTorch is concerned, it is just a bunch of numbers in memory.\n\nThe length of a tensor's shape is its rank:","metadata":{}},{"cell_type":"code","source":"len(stacked_threes.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:24:13.271521Z","iopub.execute_input":"2024-02-18T01:24:13.272106Z","iopub.status.idle":"2024-02-18T01:24:13.281150Z","shell.execute_reply.started":"2024-02-18T01:24:13.272056Z","shell.execute_reply":"2024-02-18T01:24:13.279952Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"markdown","source":"We already have our independent variables x—these are the images themselves. We'll concatenate them all into a single tensor, and also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). We can do this using view, which is a PyTorch method that changes the shape of a tensor without changing its contents. -1 is a special parameter to view that means \"make this axis as big as necessary to fit all the data\":","metadata":{}},{"cell_type":"code","source":"train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:26:43.970207Z","iopub.execute_input":"2024-02-18T01:26:43.970903Z","iopub.status.idle":"2024-02-18T01:26:44.008121Z","shell.execute_reply.started":"2024-02-18T01:26:43.970846Z","shell.execute_reply":"2024-02-18T01:26:44.006777Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Label each image. 1 for 3's and 0 for 7's. Combine these labels into a tensor `train_y`.","metadata":{}},{"cell_type":"code","source":"train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\ntrain_x.shape, train_y.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:28:09.363439Z","iopub.execute_input":"2024-02-18T01:28:09.363914Z","iopub.status.idle":"2024-02-18T01:28:09.383550Z","shell.execute_reply.started":"2024-02-18T01:28:09.363872Z","shell.execute_reply":"2024-02-18T01:28:09.382262Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(torch.Size([12396, 784]), torch.Size([12396, 1]))"},"metadata":{}}]},{"cell_type":"markdown","source":"A Dataset in PyTorch is required to return a tuple of (x,y) when indexed. Python provides a zip function which, when combined with list, provides a simple way to get this functionality. This combines the input and expected output into a list of tuples.","metadata":{}},{"cell_type":"code","source":"dset = list(zip(train_x, train_y))\nx,y = dset[0]\nx.shape,y","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:30:04.224632Z","iopub.execute_input":"2024-02-18T01:30:04.225093Z","iopub.status.idle":"2024-02-18T01:30:05.015438Z","shell.execute_reply.started":"2024-02-18T01:30:04.225047Z","shell.execute_reply":"2024-02-18T01:30:05.014431Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(torch.Size([784]), tensor([1]))"},"metadata":{}}]},{"cell_type":"markdown","source":"Now do the same thing for the validation data. Need to concatenate the validation image tensors, then create a `valid_y` tensor that labels what each of the validation data points are. Then can combine these two into a Dataset just like the training data.","metadata":{}},{"cell_type":"code","source":"valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\nvalid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\nvalid_dset = list(zip(valid_x, valid_y))\nx,y = valid_dset[0]\nx.shape, y","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:36:21.263825Z","iopub.execute_input":"2024-02-18T01:36:21.264337Z","iopub.status.idle":"2024-02-18T01:36:21.289098Z","shell.execute_reply.started":"2024-02-18T01:36:21.264292Z","shell.execute_reply":"2024-02-18T01:36:21.288160Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(torch.Size([784]), tensor([1]))"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we need an initially random weight for every pixel (this is the initialize step in our 7 step process):","metadata":{}},{"cell_type":"code","source":"def init_params(size, std=1.0):\n    return (torch.randn(size)*std).requires_grad_()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:37:39.342019Z","iopub.execute_input":"2024-02-18T01:37:39.342562Z","iopub.status.idle":"2024-02-18T01:37:39.349143Z","shell.execute_reply.started":"2024-02-18T01:37:39.342521Z","shell.execute_reply":"2024-02-18T01:37:39.348070Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"weights = init_params((28*28,1))","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:38:04.726028Z","iopub.execute_input":"2024-02-18T01:38:04.726506Z","iopub.status.idle":"2024-02-18T01:38:04.739817Z","shell.execute_reply.started":"2024-02-18T01:38:04.726466Z","shell.execute_reply":"2024-02-18T01:38:04.738461Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Initialize `b` to a random number as well!","metadata":{}},{"cell_type":"code","source":"bias = init_params(1)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:38:48.936670Z","iopub.execute_input":"2024-02-18T01:38:48.937707Z","iopub.status.idle":"2024-02-18T01:38:48.944773Z","shell.execute_reply.started":"2024-02-18T01:38:48.937644Z","shell.execute_reply":"2024-02-18T01:38:48.943229Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"In neural networks, the `w` in the equation `y=w*x+b` is called the weights, and `b` is called the bias. Together, the weights and bias make up the parameters.","metadata":{}},{"cell_type":"markdown","source":"We can now calculate a prediction for one image.","metadata":{}},{"cell_type":"code","source":"(train_x[0]*weights.T).sum() + bias","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:40:23.977413Z","iopub.execute_input":"2024-02-18T01:40:23.977880Z","iopub.status.idle":"2024-02-18T01:40:24.026627Z","shell.execute_reply.started":"2024-02-18T01:40:23.977842Z","shell.execute_reply":"2024-02-18T01:40:24.025095Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"tensor([1.4574], grad_fn=<AddBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"While we could use a Python for loop to calculate the prediction for each image, that would be very slow. Because Python loops don't run on the GPU, and because Python is a slow language for loops in general, we need to represent as much of the computation in a model as possible using higher-level functions.\n\nIn this case, there's an extremely convenient mathematical operation that calculates w*x for every row of a matrix—it's called matrix multiplication.\n\nIn Python, matrix multiplication is represented with the `@` operator. ","metadata":{}},{"cell_type":"code","source":"def linear1(xb):\n    return xb@weights + bias\n\npreds = linear1(train_x)\npreds","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:42:31.681942Z","iopub.execute_input":"2024-02-18T01:42:31.682478Z","iopub.status.idle":"2024-02-18T01:42:31.710183Z","shell.execute_reply.started":"2024-02-18T01:42:31.682419Z","shell.execute_reply":"2024-02-18T01:42:31.709125Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"tensor([[  1.4574],\n        [ 15.8800],\n        [  2.2931],\n        ...,\n        [-22.3284],\n        [-12.8770],\n        [-18.6255]], grad_fn=<AddBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"Here we make use of the `@` operator to execute matrix multiplication. This multiplies the tensor that is passed into the `linear` function by the `weights` tensor and adds the resulting tensor to the `bias` tensor. This should return a tensor with a single value for each image in the input parameter. This value represents a prediction for each image.\n\nThe first element is the same as what we calculated before manually. This should indicate to you they are doing the same math behind the scenes.","metadata":{}},{"cell_type":"markdown","source":"Let's check our accuracy. To decide if an output represents a 3 or a 7, we can just check whether its greater than 0.0, so our accuracy for each item can be calcuated (using broadcasting, so no loops!) with:","metadata":{}},{"cell_type":"code","source":"corrects = (preds>0.0).float() == train_y\ncorrects","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:46:08.215686Z","iopub.execute_input":"2024-02-18T01:46:08.216270Z","iopub.status.idle":"2024-02-18T01:46:08.227021Z","shell.execute_reply.started":"2024-02-18T01:46:08.216223Z","shell.execute_reply":"2024-02-18T01:46:08.225670Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"tensor([[True],\n        [True],\n        [True],\n        ...,\n        [True],\n        [True],\n        [True]])"},"metadata":{}}]},{"cell_type":"code","source":"corrects.float().mean().item()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:46:19.370422Z","iopub.execute_input":"2024-02-18T01:46:19.371696Z","iopub.status.idle":"2024-02-18T01:46:19.379157Z","shell.execute_reply.started":"2024-02-18T01:46:19.371650Z","shell.execute_reply":"2024-02-18T01:46:19.377822Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0.7455630898475647"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's see what the change in accuracy is given a very small change to the weights.","metadata":{}},{"cell_type":"code","source":"with torch.no_grad(): weights[0] *= 1.0001","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:47:02.379256Z","iopub.execute_input":"2024-02-18T01:47:02.379756Z","iopub.status.idle":"2024-02-18T01:47:02.388190Z","shell.execute_reply.started":"2024-02-18T01:47:02.379715Z","shell.execute_reply":"2024-02-18T01:47:02.386960Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"preds = linear1(train_x)\n((preds>0.0).float() == train_y).float().mean().item()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:47:07.395526Z","iopub.execute_input":"2024-02-18T01:47:07.396004Z","iopub.status.idle":"2024-02-18T01:47:07.408508Z","shell.execute_reply.started":"2024-02-18T01:47:07.395961Z","shell.execute_reply":"2024-02-18T01:47:07.407242Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"0.7455630898475647"},"metadata":{}}]},{"cell_type":"markdown","source":"As we've seen, we need gradients in order to improve our model using SGD, and in order to calculate gradients we need some loss function that represents how good our model is. That is because the gradients are a measure of how that loss function changes with small tweaks to the weights.\n\nSo, we need to choose a loss function. The obvious approach would be to use accuracy, which is our metric, as our loss function as well. In this case, we would calculate our prediction for each image, collect these values to calculate an overall accuracy, and then calculate the gradients of each weight with respect to that overall accuracy.\n\nUnfortunately, we have a significant technical problem here. The gradient of a function is its slope, or its steepness, which can be defined as rise over run—that is, how much the value of the function goes up or down, divided by how much we changed the input. We can write this in mathematically as: (y_new - y_old) / (x_new - x_old). This gives us a good approximation of the gradient when x_new is very similar to x_old, meaning that their difference is very small. But accuracy only changes at all when a prediction changes from a 3 to a 7, or vice versa. The problem is that a small change in weights from x_old to x_new isn't likely to cause any prediction to change, so (y_new - y_old) will almost always be 0. In other words, the gradient is 0 almost everywhere.\n\nA very small change in the value of a weight will often not actually change the accuracy at all. This means it is not useful to use accuracy as a loss function—if we do, most of the time our gradients will actually be 0, and the model will not be able to learn from that number.\n\nInstead, we need a loss function which, when our weights result in slightly better predictions, gives us a slightly better loss. So what does a \"slightly better prediction\" look like, exactly? Well, in this case, it means that if the correct answer is a 3 the score is a little higher, or if the correct answer is a 7 the score is a little lower.","metadata":{}},{"cell_type":"markdown","source":"Let's write such a function now. What form does it take?\n\nThe loss function receives not the images themselves, but the predictions from the model. Let's make one argument, prds, of values between 0 and 1, where each value is the prediction that an image is a 3. It is a vector (i.e., a rank-1 tensor), indexed over the images.\n\nThe purpose of the loss function is to measure the difference between predicted values and the true values — that is, the targets (aka labels). Let's make another argument, trgts, with values of 0 or 1 which tells whether an image actually is a 3 or not. It is also a vector (i.e., another rank-1 tensor), indexed over the images.\n\nSo, for instance, suppose we had three images which we knew were a 3, a 7, and a 3. And suppose our model predicted with high confidence (0.9) that the first was a 3, with slight confidence (0.4) that the second was a 7, and with fair confidence (0.2), but incorrectly, that the last was a 7. This would mean our loss function would receive these values as its inputs:","metadata":{}},{"cell_type":"code","source":"trgts  = tensor([1,0,1])\nprds   = tensor([0.9, 0.4, 0.2])","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:49:41.369471Z","iopub.execute_input":"2024-02-18T01:49:41.369973Z","iopub.status.idle":"2024-02-18T01:49:41.376835Z","shell.execute_reply.started":"2024-02-18T01:49:41.369935Z","shell.execute_reply":"2024-02-18T01:49:41.375722Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Here's a first try at a loss function that measures the distance between predictions and targets:","metadata":{}},{"cell_type":"code","source":"def mnist_loss(predictions, targets):\n    return torch.where(targets==1, 1-predictions, predictions).mean()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:50:00.219217Z","iopub.execute_input":"2024-02-18T01:50:00.219682Z","iopub.status.idle":"2024-02-18T01:50:00.226472Z","shell.execute_reply.started":"2024-02-18T01:50:00.219643Z","shell.execute_reply":"2024-02-18T01:50:00.224980Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"We're using a new function, torch.where(a,b,c). This is the same as running the list comprehension [b[i] if a[i] else c[i] for i in range(len(a))], except it works on tensors, at C/CUDA speed. In plain English, this function will measure how distant each prediction is from 1 if it should be 1, and how distant it is from 0 if it should be 0, and then it will take the mean of all those distances.\n\nnote: Read the Docs: It's important to learn about PyTorch functions like this, because looping over tensors in Python performs at Python speed, not C/CUDA speed! Try running help(torch.where) now to read the docs for this function, or, better still, look it up on the PyTorch documentation site.","metadata":{}},{"cell_type":"code","source":"help(torch.where)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:51:08.334162Z","iopub.execute_input":"2024-02-18T01:51:08.334671Z","iopub.status.idle":"2024-02-18T01:51:08.344173Z","shell.execute_reply.started":"2024-02-18T01:51:08.334625Z","shell.execute_reply":"2024-02-18T01:51:08.342460Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Help on built-in function where in module torch:\n\nwhere(...)\n    where(condition, input, other, *, out=None) -> Tensor\n    \n    Return a tensor of elements selected from either :attr:`input` or :attr:`other`, depending on :attr:`condition`.\n    \n    The operation is defined as:\n    \n    .. math::\n        \\text{out}_i = \\begin{cases}\n            \\text{input}_i & \\text{if } \\text{condition}_i \\\\\n            \\text{other}_i & \\text{otherwise} \\\\\n        \\end{cases}\n    \n    .. note::\n        The tensors :attr:`condition`, :attr:`input`, :attr:`other` must be :ref:`broadcastable <broadcasting-semantics>`.\n    \n    Arguments:\n        condition (BoolTensor): When True (nonzero), yield input, otherwise yield other\n        input (Tensor or Scalar): value (if :attr:`input` is a scalar) or values selected at indices\n                              where :attr:`condition` is ``True``\n        other (Tensor or Scalar): value (if :attr:`other` is a scalar) or values selected at indices\n                              where :attr:`condition` is ``False``\n    \n    Keyword args:\n        out (Tensor, optional): the output tensor.\n    \n    Returns:\n        Tensor: A tensor of shape equal to the broadcasted shape of :attr:`condition`, :attr:`input`, :attr:`other`\n    \n    Example::\n    \n        >>> x = torch.randn(3, 2)\n        >>> y = torch.ones(3, 2)\n        >>> x\n        tensor([[-0.4620,  0.3139],\n                [ 0.3898, -0.7197],\n                [ 0.0478, -0.1657]])\n        >>> torch.where(x > 0, 1.0, 0.0)\n        tensor([[0., 1.],\n                [1., 0.],\n                [1., 0.]])\n        >>> torch.where(x > 0, x, y)\n        tensor([[ 1.0000,  0.3139],\n                [ 0.3898,  1.0000],\n                [ 0.0478,  1.0000]])\n        >>> x = torch.randn(2, 2, dtype=torch.double)\n        >>> x\n        tensor([[ 1.0779,  0.0383],\n                [-0.8785, -1.1089]], dtype=torch.float64)\n        >>> torch.where(x > 0, x, 0.)\n        tensor([[1.0779, 0.0383],\n                [0.0000, 0.0000]], dtype=torch.float64)\n    \n    .. function:: where(condition) -> tuple of LongTensor\n       :noindex:\n    \n    ``torch.where(condition)`` is identical to\n    ``torch.nonzero(condition, as_tuple=True)``.\n    \n    .. note::\n        See also :func:`torch.nonzero`.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"From Chat GPT:","metadata":{}},{"cell_type":"markdown","source":"torch.where() is a PyTorch function that returns a tensor with elements selected from either the x tensor or the y tensor, depending on the condition specified. It has the following syntax:\n\n`torch.where(condition, x, y)`\n\ncondition: This is a boolean tensor that specifies which elements to choose from x or y. Wherever the condition is True, the corresponding element from x is selected; otherwise, the corresponding element from y is selected.\n\nx: This is the tensor containing elements to choose from where the condition is True.\n\ny: This is the tensor containing elements to choose from where the condition is False.\n\nIn the mnist_loss function, predictions are the output probabilities from the model, and targets are the ground truth labels (binary in this case, usually 0 or 1 for binary classification tasks like MNIST digit classification).\n\nSo, the torch.where(targets==1, 1-predictions, predictions) call does the following:\n\nWherever targets is equal to 1 (indicating the positive class), it selects 1-predictions. This means if the target is 1 (positive class), it wants the loss to be high when the prediction is low (close to 0), hence 1-predictions.\n\nWherever targets is not equal to 1 (indicating the negative class), it selects predictions. This means if the target is not 1 (negative class), it wants the loss to be high when the prediction is high (close to 1), hence predictions.\n\nFinally, .mean() computes the mean of all the selected elements, which represents the average loss across all samples in the batch.\n\nIn summary, the mnist_loss function computes a binary cross-entropy loss for binary classification tasks like MNIST digit classification, penalizing incorrect predictions differently based on whether they are for the positive or negative class.","metadata":{}},{"cell_type":"markdown","source":"Let's try it on our prds and trgts:","metadata":{}},{"cell_type":"code","source":"torch.where(trgts==1, 1-prds, prds)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:55:47.567520Z","iopub.execute_input":"2024-02-18T01:55:47.568035Z","iopub.status.idle":"2024-02-18T01:55:47.581162Z","shell.execute_reply.started":"2024-02-18T01:55:47.567993Z","shell.execute_reply":"2024-02-18T01:55:47.579817Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"tensor([0.1000, 0.4000, 0.8000])"},"metadata":{}}]},{"cell_type":"code","source":"mnist_loss(prds,trgts)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:56:13.561653Z","iopub.execute_input":"2024-02-18T01:56:13.562249Z","iopub.status.idle":"2024-02-18T01:56:13.573296Z","shell.execute_reply.started":"2024-02-18T01:56:13.562198Z","shell.execute_reply":"2024-02-18T01:56:13.571952Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"tensor(0.4333)"},"metadata":{}}]},{"cell_type":"markdown","source":"One problem with mnist_loss as currently defined is that it assumes that predictions are always between 0 and 1. We need to ensure, then, that this is actually the case! As it happens, there is a function that does exactly that—let's take a look.","metadata":{}},{"cell_type":"markdown","source":"The sigmoid function always outputs a number between 0 and 1. It's defined as follows:","metadata":{}},{"cell_type":"code","source":"def sigmoid(x): return 1/(1+torch.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:56:59.884912Z","iopub.execute_input":"2024-02-18T01:56:59.885508Z","iopub.status.idle":"2024-02-18T01:56:59.891934Z","shell.execute_reply.started":"2024-02-18T01:56:59.885441Z","shell.execute_reply":"2024-02-18T01:56:59.890616Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"Let's update mnist_loss to first apply sigmoid to the inputs:","metadata":{}},{"cell_type":"code","source":"def mnist_loss(predictions, targets):\n    predictions = predictions.sigmoid()\n    return torch.where(targets==1, 1-predictions, predictions).mean()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T01:57:27.134076Z","iopub.execute_input":"2024-02-18T01:57:27.134697Z","iopub.status.idle":"2024-02-18T01:57:27.141475Z","shell.execute_reply.started":"2024-02-18T01:57:27.134639Z","shell.execute_reply":"2024-02-18T01:57:27.140269Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Having defined a loss function, now is a good moment to recapitulate why we did this. After all, we already had a metric, which was overall accuracy. So why did we define a loss?\n\nThe key difference is that the metric is to drive human understanding and the loss is to drive automated learning. To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level. This requirement means that sometimes it does not really reflect exactly what we are trying to achieve, but is rather a compromise between our real goal and a function that can be optimized using its gradient. The loss function is calculated for each item in our dataset, and then at the end of an epoch the loss values are all averaged and the overall mean is reported for the epoch.\n\nMetrics, on the other hand, are the numbers that we really care about. These are the values that are printed at the end of each epoch that tell us how our model is really doing. It is important that we learn to focus on these metrics, rather than the loss, when judging the performance of a model.","metadata":{}},{"cell_type":"markdown","source":"Now that we have a loss function that is suitable for driving SGD, we can consider some of the details involved in the next phase of the learning process, which is to change or update the weights based on the gradients. This is called an optimization step.","metadata":{}},{"cell_type":"markdown","source":"we calculate the average loss for a few data items at a time. This is called a mini-batch. The number of data items in the mini-batch is called the batch size. A larger batch size means that you will get a more accurate and stable estimate of your dataset's gradients from the loss function, but it will take longer, and you will process fewer mini-batches per epoch. Choosing a good batch size is one of the decisions you need to make as a deep learning practitioner to train your model quickly and accurately. ","metadata":{}},{"cell_type":"markdown","source":"Instead of simply enumerating our dataset in order for every epoch, we randomly shuffle our dataset on every epoch, before we create mini-batchs. PyTorch and fastai provide a class that will do the shuffling and mini-batch collation for you called a `DataLoader`.\n\nA `DataLoader` can take any Python collection and turn it into an iterator over mini-batchs, like so:","metadata":{}},{"cell_type":"code","source":"coll = range(15)\ndl = DataLoader(coll, batch_size=5, shuffle=True)\nlist(dl)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:26:18.842653Z","iopub.execute_input":"2024-02-18T02:26:18.843125Z","iopub.status.idle":"2024-02-18T02:26:18.858229Z","shell.execute_reply.started":"2024-02-18T02:26:18.843089Z","shell.execute_reply":"2024-02-18T02:26:18.856970Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"[tensor([ 2,  9,  6,  8, 10]),\n tensor([ 7,  5, 11,  4, 14]),\n tensor([12, 13,  3,  1,  0])]"},"metadata":{}}]},{"cell_type":"markdown","source":"For training a model, we want a collection containing independent and dependent variables (inputs and targets of the model). A collection that contains tuples of independent and dependent variables is known in PyTorch as a Dataset. Here's an example of an extremely simple Dataset:","metadata":{}},{"cell_type":"code","source":"ds = L(enumerate(string.ascii_lowercase))\nds","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:27:26.381026Z","iopub.execute_input":"2024-02-18T02:27:26.381562Z","iopub.status.idle":"2024-02-18T02:27:26.391084Z","shell.execute_reply.started":"2024-02-18T02:27:26.381524Z","shell.execute_reply":"2024-02-18T02:27:26.389460Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"},"metadata":{}}]},{"cell_type":"markdown","source":"When we pass a Dataset to a DataLoader we will get back mini-batches which are themselves tuples of tensors representing batches of independent and dependent variables:","metadata":{}},{"cell_type":"code","source":"dl = DataLoader(ds, batch_size=6, shuffle=True)\nlist(dl)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:27:51.580672Z","iopub.execute_input":"2024-02-18T02:27:51.581444Z","iopub.status.idle":"2024-02-18T02:27:51.594244Z","shell.execute_reply.started":"2024-02-18T02:27:51.581398Z","shell.execute_reply":"2024-02-18T02:27:51.592798Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"[(tensor([12, 24,  3, 14, 21,  8]), ('m', 'y', 'd', 'o', 'v', 'i')),\n (tensor([22,  0, 10,  2, 20,  6]), ('w', 'a', 'k', 'c', 'u', 'g')),\n (tensor([ 1, 15, 13, 16,  9,  5]), ('b', 'p', 'n', 'q', 'j', 'f')),\n (tensor([19, 17, 23, 18,  4, 25]), ('t', 'r', 'x', 's', 'e', 'z')),\n (tensor([ 7, 11]), ('h', 'l'))]"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we can get started training our MNIST model using SGD!\n\nFirst let's re-initialize our parameters:","metadata":{}},{"cell_type":"code","source":"weights = init_params((28*28,1))\nbias = init_params(1)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:29:57.280817Z","iopub.execute_input":"2024-02-18T02:29:57.281311Z","iopub.status.idle":"2024-02-18T02:29:57.286793Z","shell.execute_reply.started":"2024-02-18T02:29:57.281273Z","shell.execute_reply":"2024-02-18T02:29:57.285706Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"A `DataLoader` can be created from a `Dataset`:","metadata":{}},{"cell_type":"code","source":"# dset is the tensor of tuples we created earlier with the\n# input and correct answers for the training data\n\ndl = DataLoader(dset, batch_size=256)\nxb,yb = first(dl)\nxb.shape,yb.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:30:30.784819Z","iopub.execute_input":"2024-02-18T02:30:30.785690Z","iopub.status.idle":"2024-02-18T02:30:30.798968Z","shell.execute_reply.started":"2024-02-18T02:30:30.785638Z","shell.execute_reply":"2024-02-18T02:30:30.797547Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(torch.Size([256, 784]), torch.Size([256, 1]))"},"metadata":{}}]},{"cell_type":"markdown","source":"We'll do the same for the validation set:","metadata":{}},{"cell_type":"code","source":"# valid_dset is the tensor of tuples we created earlier with the\n# input and correct answers for the validation data\n\nvalid_dl = DataLoader(valid_dset, batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:32:18.209619Z","iopub.execute_input":"2024-02-18T02:32:18.210381Z","iopub.status.idle":"2024-02-18T02:32:18.216913Z","shell.execute_reply.started":"2024-02-18T02:32:18.210326Z","shell.execute_reply":"2024-02-18T02:32:18.215331Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Let's create a mini-batch of size 4 for testing:","metadata":{}},{"cell_type":"code","source":"batch = train_x[:4]\nbatch.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:32:57.546584Z","iopub.execute_input":"2024-02-18T02:32:57.547034Z","iopub.status.idle":"2024-02-18T02:32:57.555255Z","shell.execute_reply.started":"2024-02-18T02:32:57.546999Z","shell.execute_reply":"2024-02-18T02:32:57.553839Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 784])"},"metadata":{}}]},{"cell_type":"markdown","source":"Then feed that mini-batch into our model","metadata":{}},{"cell_type":"code","source":"preds = linear1(batch)\npreds","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:33:27.604524Z","iopub.execute_input":"2024-02-18T02:33:27.605011Z","iopub.status.idle":"2024-02-18T02:33:27.615831Z","shell.execute_reply.started":"2024-02-18T02:33:27.604977Z","shell.execute_reply":"2024-02-18T02:33:27.614289Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"tensor([[ -6.4616],\n        [ -5.7044],\n        [-12.4600],\n        [ -2.5384]], grad_fn=<AddBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"Calculate the loss:","metadata":{}},{"cell_type":"code","source":"# use train_y[:4] b/c the mini-batch was made from the first 4\n# training data in train_x\n\nloss = mnist_loss(preds, train_y[:4])\nloss","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:34:34.720059Z","iopub.execute_input":"2024-02-18T02:34:34.720944Z","iopub.status.idle":"2024-02-18T02:34:34.733010Z","shell.execute_reply.started":"2024-02-18T02:34:34.720898Z","shell.execute_reply":"2024-02-18T02:34:34.731573Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"tensor(0.9805, grad_fn=<MeanBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we can calculate the graidents. Once we have the gradients, we can use that to step our parameters and improve the model!","metadata":{}},{"cell_type":"code","source":"# calc gradients on the loss (step need to min(loss))\n\nloss.backward()\n\n# gradients are calc'd and stored on each param as a tensor\n\nweights.grad.shape,weights.grad.mean(),bias.grad","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:36:14.771243Z","iopub.execute_input":"2024-02-18T02:36:14.771812Z","iopub.status.idle":"2024-02-18T02:36:15.035351Z","shell.execute_reply.started":"2024-02-18T02:36:14.771767Z","shell.execute_reply":"2024-02-18T02:36:15.034125Z"},"trusted":true},"execution_count":52,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# calc gradients on the loss (step need to min(loss))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# gradients are calc'd and stored on each param as a tensor\u001b[39;00m\n\u001b[1;32m      7\u001b[0m weights\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mshape,weights\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mmean(),bias\u001b[38;5;241m.\u001b[39mgrad\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."],"ename":"RuntimeError","evalue":"Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.","output_type":"error"}]},{"cell_type":"markdown","source":"That is the bulk of the training steps. After that we'd just need to actually update the parameters.\n\nBefore we do that, let's put those steps we just covered in a function. It should:\n1. generate a prediction based on a batch of input data\n2. calculate the loss on the predictions (how accurate it was)\n3. calculate the gradients","metadata":{}},{"cell_type":"code","source":"def calc_grad(xb, yb, model):\n    preds = model(xb)\n    loss = mnist_loss(preds, yb)\n    loss.backward()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:40:28.259824Z","iopub.execute_input":"2024-02-18T02:40:28.260515Z","iopub.status.idle":"2024-02-18T02:40:28.268218Z","shell.execute_reply.started":"2024-02-18T02:40:28.260466Z","shell.execute_reply":"2024-02-18T02:40:28.266788Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"Now test it using our test mini-batch:","metadata":{}},{"cell_type":"code","source":"calc_grad(batch, train_y[:4], linear1)\nweights.grad.mean(),bias.grad","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:41:42.083706Z","iopub.execute_input":"2024-02-18T02:41:42.084601Z","iopub.status.idle":"2024-02-18T02:41:42.096311Z","shell.execute_reply.started":"2024-02-18T02:41:42.084551Z","shell.execute_reply":"2024-02-18T02:41:42.094663Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"(tensor(-0.0063), tensor([-0.0364]))"},"metadata":{}}]},{"cell_type":"markdown","source":"But look what happens if we call it twice:","metadata":{}},{"cell_type":"code","source":"calc_grad(batch, train_y[:4], linear1)\nweights.grad.mean(),bias.grad","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:42:03.937921Z","iopub.execute_input":"2024-02-18T02:42:03.938418Z","iopub.status.idle":"2024-02-18T02:42:03.950628Z","shell.execute_reply.started":"2024-02-18T02:42:03.938354Z","shell.execute_reply":"2024-02-18T02:42:03.949420Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"(tensor(-0.0095), tensor([-0.0545]))"},"metadata":{}}]},{"cell_type":"markdown","source":"The gradients have changed! The reason for this is that loss.backward actually adds the gradients of loss to any gradients that are currently stored. So, we have to set the current gradients to 0 first:","metadata":{}},{"cell_type":"code","source":"weights.grad.zero_()\nbias.grad.zero_();","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:42:31.935714Z","iopub.execute_input":"2024-02-18T02:42:31.936194Z","iopub.status.idle":"2024-02-18T02:42:31.944709Z","shell.execute_reply.started":"2024-02-18T02:42:31.936157Z","shell.execute_reply":"2024-02-18T02:42:31.943151Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"note: Inplace Operations: Methods in PyTorch whose names end in an underscore modify their objects in place. For instance, bias.zero_() sets all elements of the tensor bias to 0.","metadata":{}},{"cell_type":"markdown","source":"Our only remaining step is to update the weights and biases based on the gradient and learning rate. When we do so, we have to tell PyTorch not to take the gradient of this step too—otherwise things will get very confusing when we try to compute the derivative at the next batch! If we assign to the data attribute of a tensor then PyTorch will not take the gradient of that step. Here's our basic training loop for an epoch:","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, lr, params):\n    for xb, yb in dl:\n        calc_grad(xb, yb, model)\n        for p in params:\n            p.data -= p.grad*lr\n            p.grad.zero_()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:44:42.488303Z","iopub.execute_input":"2024-02-18T02:44:42.490005Z","iopub.status.idle":"2024-02-18T02:44:42.497697Z","shell.execute_reply.started":"2024-02-18T02:44:42.489932Z","shell.execute_reply":"2024-02-18T02:44:42.496454Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"We also want to check how we're doing, by looking at the accuracy of the validation set. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0. So our accuracy for each item can be calculated (using broadcasting, so no loops!) with:","metadata":{}},{"cell_type":"code","source":"(preds>0.0).float() == train_y[:4]","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:45:05.441977Z","iopub.execute_input":"2024-02-18T02:45:05.442447Z","iopub.status.idle":"2024-02-18T02:45:05.452225Z","shell.execute_reply.started":"2024-02-18T02:45:05.442411Z","shell.execute_reply":"2024-02-18T02:45:05.450736Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"tensor([[False],\n        [False],\n        [False],\n        [False]])"},"metadata":{}}]},{"cell_type":"markdown","source":"That gives us this function to calculate our validation accuracy:","metadata":{}},{"cell_type":"code","source":"def batch_accuracy(xb, yb):\n    preds = xb.sigmoid()\n    correct = (preds>0.5) == yb\n    return correct.float().mean()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:46:23.132382Z","iopub.execute_input":"2024-02-18T02:46:23.133995Z","iopub.status.idle":"2024-02-18T02:46:23.141383Z","shell.execute_reply.started":"2024-02-18T02:46:23.133917Z","shell.execute_reply":"2024-02-18T02:46:23.140375Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# test out batch_accuracy with test mini-batch\n\nbatch_accuracy(linear1(batch), train_y[:4])","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:46:45.886110Z","iopub.execute_input":"2024-02-18T02:46:45.886688Z","iopub.status.idle":"2024-02-18T02:46:45.898791Z","shell.execute_reply.started":"2024-02-18T02:46:45.886646Z","shell.execute_reply":"2024-02-18T02:46:45.897194Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"tensor(0.)"},"metadata":{}}]},{"cell_type":"markdown","source":"Put the batches together","metadata":{}},{"cell_type":"code","source":"def validate_epoch(model):\n    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n    return round(torch.stack(accs).mean().item(), 4)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:47:26.566846Z","iopub.execute_input":"2024-02-18T02:47:26.567308Z","iopub.status.idle":"2024-02-18T02:47:26.573855Z","shell.execute_reply.started":"2024-02-18T02:47:26.567277Z","shell.execute_reply":"2024-02-18T02:47:26.572314Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"validate_epoch(linear1)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:48:03.923705Z","iopub.execute_input":"2024-02-18T02:48:03.924452Z","iopub.status.idle":"2024-02-18T02:48:03.948802Z","shell.execute_reply.started":"2024-02-18T02:48:03.924414Z","shell.execute_reply":"2024-02-18T02:48:03.947586Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"0.4958"},"metadata":{}}]},{"cell_type":"markdown","source":"That's our starting point. Let's train for one epoch, and see if the accuracy improves:","metadata":{}},{"cell_type":"code","source":"lr = 1.\nparams = weights,bias\ntrain_epoch(linear1, lr, params)\nvalidate_epoch(linear1)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:48:52.692928Z","iopub.execute_input":"2024-02-18T02:48:52.693401Z","iopub.status.idle":"2024-02-18T02:48:52.807971Z","shell.execute_reply.started":"2024-02-18T02:48:52.693354Z","shell.execute_reply":"2024-02-18T02:48:52.806735Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"0.6414"},"metadata":{}}]},{"cell_type":"markdown","source":"Then do a few more:","metadata":{}},{"cell_type":"code","source":"for i in range(20):\n    train_epoch(linear1, lr, params)\n    print(validate_epoch(linear1), end=' ')","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:49:46.199640Z","iopub.execute_input":"2024-02-18T02:49:46.200112Z","iopub.status.idle":"2024-02-18T02:49:48.117839Z","shell.execute_reply.started":"2024-02-18T02:49:46.200079Z","shell.execute_reply":"2024-02-18T02:49:48.115184Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"0.8353 0.9037 0.9276 0.9369 0.9437 0.9481 0.9496 0.951 0.952 0.9545 0.9574 0.9584 0.9593 0.9598 0.9628 0.9632 0.9637 0.9632 0.9637 0.9637 ","output_type":"stream"}]},{"cell_type":"markdown","source":"Our next step will be to create an object that will handle the SGD step for us. In PyTorch, it's called an optimizer.","metadata":{}},{"cell_type":"markdown","source":"PyTorch has some built in helper functions in its API we can use to accomplish this. The first thing we can do is replace our `linear1` function with PyTorch's `nn.Linear` module. A module is an objet of a class that inherits from the PyTorch `nn.Module` class. Objects of this class behave identically to standard Python functions, in that you can call them using parentheses and they will return the activations of a model.\n\n`nn.Linear` does the same thing as our `init_params` and `linear` together. It contains both the weights and biases in a single class. Here's how we replicate our model from the previous section:","metadata":{}},{"cell_type":"code","source":"linear_model = nn.Linear(28*28,1)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:53:26.998932Z","iopub.execute_input":"2024-02-18T02:53:26.999463Z","iopub.status.idle":"2024-02-18T02:53:27.007185Z","shell.execute_reply.started":"2024-02-18T02:53:26.999425Z","shell.execute_reply":"2024-02-18T02:53:27.005443Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"Every PyTorch module knows what parameters it has that can be trained; they are available through the parameters method:","metadata":{}},{"cell_type":"code","source":"w,b = linear_model.parameters()\nw.shape,b.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:53:44.374996Z","iopub.execute_input":"2024-02-18T02:53:44.375528Z","iopub.status.idle":"2024-02-18T02:53:44.384471Z","shell.execute_reply.started":"2024-02-18T02:53:44.375488Z","shell.execute_reply":"2024-02-18T02:53:44.382985Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"(torch.Size([1, 784]), torch.Size([1]))"},"metadata":{}}]},{"cell_type":"markdown","source":"For more information on the PyTorch `nn.Linear` module, see the PyTorch docs:\nhttps://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n\n```python\nCLASStorch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n```\n\nParameters\nin_features (int) – size of each input sample\n\nout_features (int) – size of each output sample\n\nbias (bool) – If set to False, the layer will not learn an additive bias. Default: True","metadata":{}},{"cell_type":"markdown","source":"We can now create the optimizer:","metadata":{}},{"cell_type":"code","source":"class BasicOptim:\n    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n\n    def step(self, *args, **kwargs):\n        for p in self.params: p.data -= p.grad.data * self.lr\n\n    def zero_grad(self, *args, **kwargs):\n        for p in self.params: p.grad = None","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:57:30.806459Z","iopub.execute_input":"2024-02-18T02:57:30.806991Z","iopub.status.idle":"2024-02-18T02:57:30.816352Z","shell.execute_reply.started":"2024-02-18T02:57:30.806953Z","shell.execute_reply":"2024-02-18T02:57:30.814797Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# init optimizer using PyTorch model params\n\nopt = BasicOptim(linear_model.parameters(), lr)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:58:06.693176Z","iopub.execute_input":"2024-02-18T02:58:06.693629Z","iopub.status.idle":"2024-02-18T02:58:06.699181Z","shell.execute_reply.started":"2024-02-18T02:58:06.693595Z","shell.execute_reply":"2024-02-18T02:58:06.698214Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"Our training loop can now be simplified to:","metadata":{}},{"cell_type":"code","source":"def train_epoch(model):\n    for xb,yb in dl:\n        calc_grad(xb, yb, model)\n        opt.step()\n        opt.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:58:59.110639Z","iopub.execute_input":"2024-02-18T02:58:59.111124Z","iopub.status.idle":"2024-02-18T02:58:59.117579Z","shell.execute_reply.started":"2024-02-18T02:58:59.111085Z","shell.execute_reply":"2024-02-18T02:58:59.116246Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"validate_epoch(linear_model)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T02:59:06.312590Z","iopub.execute_input":"2024-02-18T02:59:06.313147Z","iopub.status.idle":"2024-02-18T02:59:06.338259Z","shell.execute_reply.started":"2024-02-18T02:59:06.313106Z","shell.execute_reply":"2024-02-18T02:59:06.336931Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"0.4087"},"metadata":{}}]},{"cell_type":"markdown","source":"Create a function for the training process to make things simpler.","metadata":{}},{"cell_type":"code","source":"def train_model(model, epoch):\n    for i in range(epoch):\n        train_epoch(model)\n        print(validate_epoch(linear_model))","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:00:26.209944Z","iopub.execute_input":"2024-02-18T03:00:26.210355Z","iopub.status.idle":"2024-02-18T03:00:26.216429Z","shell.execute_reply.started":"2024-02-18T03:00:26.210324Z","shell.execute_reply":"2024-02-18T03:00:26.214943Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"train_model(linear_model, 20)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:00:26.595034Z","iopub.execute_input":"2024-02-18T03:00:26.596443Z","iopub.status.idle":"2024-02-18T03:00:28.449472Z","shell.execute_reply.started":"2024-02-18T03:00:26.596388Z","shell.execute_reply":"2024-02-18T03:00:28.448165Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"0.4932\n0.9042\n0.8086\n0.9067\n0.9311\n0.9453\n0.9555\n0.9609\n0.9653\n0.9672\n0.9687\n0.9706\n0.9736\n0.975\n0.976\n0.976\n0.9775\n0.978\n0.978\n0.9789\n","output_type":"stream"}]},{"cell_type":"markdown","source":"fastai provides the SGD class which, by default, does the same thing as our BasicOptim:","metadata":{}},{"cell_type":"code","source":"linear_model = nn.Linear(28*28,1)\nopt = SGD(linear_model.parameters(), lr)\ntrain_model(linear_model, 20)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:01:32.770604Z","iopub.execute_input":"2024-02-18T03:01:32.771057Z","iopub.status.idle":"2024-02-18T03:01:34.772638Z","shell.execute_reply.started":"2024-02-18T03:01:32.771025Z","shell.execute_reply":"2024-02-18T03:01:34.771210Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"0.4932\n0.8579\n0.8335\n0.9111\n0.9326\n0.9467\n0.9555\n0.9628\n0.9653\n0.9667\n0.9692\n0.9716\n0.9741\n0.9745\n0.976\n0.976\n0.9775\n0.9775\n0.978\n0.978\n","output_type":"stream"}]},{"cell_type":"markdown","source":"fastai also provides Learner.fit, which we can use instead of train_model. To create a Learner we first need to create a DataLoaders, by passing in our training and validation DataLoaders:","metadata":{}},{"cell_type":"code","source":"dls = DataLoaders(dl, valid_dl)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:02:33.567653Z","iopub.execute_input":"2024-02-18T03:02:33.568230Z","iopub.status.idle":"2024-02-18T03:02:33.574427Z","shell.execute_reply.started":"2024-02-18T03:02:33.568186Z","shell.execute_reply":"2024-02-18T03:02:33.572952Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"To create a Learner without using an application (such as vision_learner) we need to pass in all the elements that we've created in this chapter: the DataLoaders, the model, the optimization function (which will be passed the parameters), the loss function, and optionally any metrics to print:","metadata":{}},{"cell_type":"code","source":"learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n                loss_func=mnist_loss, metrics=batch_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:03:02.350894Z","iopub.execute_input":"2024-02-18T03:03:02.352217Z","iopub.status.idle":"2024-02-18T03:03:02.362169Z","shell.execute_reply.started":"2024-02-18T03:03:02.352169Z","shell.execute_reply":"2024-02-18T03:03:02.360793Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"Now we can call `learn.fit()`","metadata":{}},{"cell_type":"code","source":"learn.fit(10, lr=lr)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:03:23.492296Z","iopub.execute_input":"2024-02-18T03:03:23.492788Z","iopub.status.idle":"2024-02-18T03:03:25.823789Z","shell.execute_reply.started":"2024-02-18T03:03:23.492753Z","shell.execute_reply":"2024-02-18T03:03:25.822556Z"},"trusted":true},"execution_count":83,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>batch_accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.636949</td>\n      <td>0.503485</td>\n      <td>0.495584</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.525086</td>\n      <td>0.196720</td>\n      <td>0.831698</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.192815</td>\n      <td>0.177026</td>\n      <td>0.843474</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.084355</td>\n      <td>0.104670</td>\n      <td>0.913150</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.044425</td>\n      <td>0.076647</td>\n      <td>0.933759</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.028853</td>\n      <td>0.061567</td>\n      <td>0.948970</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.022471</td>\n      <td>0.052192</td>\n      <td>0.956330</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.019645</td>\n      <td>0.045948</td>\n      <td>0.962218</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.018222</td>\n      <td>0.041548</td>\n      <td>0.965653</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.017374</td>\n      <td>0.038294</td>\n      <td>0.967125</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"As you can see, there's nothing magic about the PyTorch and fastai classes. They are just convenient pre-packaged pieces that make your life a bit easier! (They also provide a lot of extra functionality we'll be using in future chapters.)\n\nWith these classes, we can now replace our linear model with a neural network.","metadata":{}},{"cell_type":"markdown","source":"So far we have a general procedure for optimizing the parameters of a function, and we have tried it out on a very boring function: a simple linear classifier. A linear classifier is very constrained in terms of what it can do. To make it a bit more complex (and able to handle more tasks), we need to add something nonlinear between two linear classifiers—this is what gives us a neural network.","metadata":{}},{"cell_type":"markdown","source":"We can implement a Neural Network using the PyTorch API","metadata":{}},{"cell_type":"code","source":"simple_net = nn.Sequential(\n    nn.Linear(28*28,30),\n    nn.ReLU(),\n    nn.Linear(30,1)\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:06:44.929689Z","iopub.execute_input":"2024-02-18T03:06:44.930231Z","iopub.status.idle":"2024-02-18T03:06:44.938680Z","shell.execute_reply.started":"2024-02-18T03:06:44.930193Z","shell.execute_reply":"2024-02-18T03:06:44.937047Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"nn.Sequential creates a module that will call each of the listed layers or functions in turn.\n\nnn.ReLU is a PyTorch module that does exactly the same thing as the F.relu function. Most functions that can appear in a model also have identical forms that are modules. Generally, it's just a case of replacing F with nn and changing the capitalization. When using nn.Sequential, PyTorch requires us to use the module version. Since modules are classes, we have to instantiate them, which is why you see nn.ReLU() in this example.\n\nBecause nn.Sequential is a module, we can get its parameters, which will return a list of all the parameters of all the modules it contains. Let's try it out! As this is a deeper model, we'll use a lower learning rate and a few more epochs.","metadata":{}},{"cell_type":"code","source":"learn = Learner(dls, simple_net, opt_func=SGD,\n                loss_func=mnist_loss, metrics=batch_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:07:46.547410Z","iopub.execute_input":"2024-02-18T03:07:46.547911Z","iopub.status.idle":"2024-02-18T03:07:46.554913Z","shell.execute_reply.started":"2024-02-18T03:07:46.547875Z","shell.execute_reply":"2024-02-18T03:07:46.553454Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"learn.fit(40, 0.1)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:07:54.589935Z","iopub.execute_input":"2024-02-18T03:07:54.590455Z","iopub.status.idle":"2024-02-18T03:08:05.544150Z","shell.execute_reply.started":"2024-02-18T03:07:54.590416Z","shell.execute_reply":"2024-02-18T03:08:05.543117Z"},"trusted":true},"execution_count":86,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>batch_accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.359349</td>\n      <td>0.369360</td>\n      <td>0.588322</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.162169</td>\n      <td>0.240583</td>\n      <td>0.793425</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.087394</td>\n      <td>0.118116</td>\n      <td>0.913150</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.055755</td>\n      <td>0.078874</td>\n      <td>0.940137</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.041351</td>\n      <td>0.061403</td>\n      <td>0.954367</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.034169</td>\n      <td>0.051662</td>\n      <td>0.963690</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.030155</td>\n      <td>0.045523</td>\n      <td>0.966634</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.027612</td>\n      <td>0.041328</td>\n      <td>0.968597</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.025815</td>\n      <td>0.038281</td>\n      <td>0.969578</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.024438</td>\n      <td>0.035965</td>\n      <td>0.970069</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.023329</td>\n      <td>0.034134</td>\n      <td>0.971541</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.022403</td>\n      <td>0.032643</td>\n      <td>0.972522</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.021614</td>\n      <td>0.031390</td>\n      <td>0.973503</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.020929</td>\n      <td>0.030316</td>\n      <td>0.974485</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.020328</td>\n      <td>0.029379</td>\n      <td>0.975466</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.019794</td>\n      <td>0.028549</td>\n      <td>0.976448</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.019316</td>\n      <td>0.027807</td>\n      <td>0.976938</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.018884</td>\n      <td>0.027141</td>\n      <td>0.977920</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.018492</td>\n      <td>0.026536</td>\n      <td>0.977920</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.018133</td>\n      <td>0.025987</td>\n      <td>0.978901</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.017802</td>\n      <td>0.025485</td>\n      <td>0.978901</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.017497</td>\n      <td>0.025025</td>\n      <td>0.978901</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.017214</td>\n      <td>0.024602</td>\n      <td>0.979882</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.016949</td>\n      <td>0.024213</td>\n      <td>0.980373</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.016701</td>\n      <td>0.023853</td>\n      <td>0.980373</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.016468</td>\n      <td>0.023521</td>\n      <td>0.980373</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.016248</td>\n      <td>0.023212</td>\n      <td>0.980373</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.016041</td>\n      <td>0.022925</td>\n      <td>0.980864</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.015844</td>\n      <td>0.022658</td>\n      <td>0.981354</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.015657</td>\n      <td>0.022409</td>\n      <td>0.981354</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.015480</td>\n      <td>0.022176</td>\n      <td>0.981354</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.015311</td>\n      <td>0.021959</td>\n      <td>0.981845</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.015150</td>\n      <td>0.021755</td>\n      <td>0.981845</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.014996</td>\n      <td>0.021563</td>\n      <td>0.982826</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.014849</td>\n      <td>0.021383</td>\n      <td>0.982826</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.014707</td>\n      <td>0.021214</td>\n      <td>0.982826</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.014572</td>\n      <td>0.021054</td>\n      <td>0.982826</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.014441</td>\n      <td>0.020902</td>\n      <td>0.982336</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.014315</td>\n      <td>0.020759</td>\n      <td>0.982336</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.014194</td>\n      <td>0.020623</td>\n      <td>0.982336</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"plt.plot(L(learn.recorder.values).itemgot(2));","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:08:21.915657Z","iopub.execute_input":"2024-02-18T03:08:21.916797Z","iopub.status.idle":"2024-02-18T03:08:22.201735Z","shell.execute_reply.started":"2024-02-18T03:08:21.916748Z","shell.execute_reply":"2024-02-18T03:08:22.200409Z"},"trusted":true},"execution_count":87,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAiwAAAGgCAYAAACJ7TzXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA530lEQVR4nO3de3xU9b3/+/fMJDOTAJmIgVwwElCBohDaKHMi2Lo3qQE9HNQeD6ItNAr+YKf9KdnWksrFW013e8oDtVhahWKvohZpd6GpmBa6rRFqkFord9BESQJBMxMScptZvz8gAyMBMpOZWZPwej4e60GystbK58vSx7z5ru/3uyyGYRgCAACIY1azCwAAALgQAgsAAIh7BBYAABD3CCwAACDuEVgAAEDcI7AAAIC4R2ABAABxj8ACAADiHoEFAADEPQILAACIeyEHlr/+9a+aPn26srKyZLFYtGHDhgues2XLFn3hC1+Qw+HQlVdeqbVr1551zMqVK5WTkyOn0ym3263t27eHWhoAAOinEkI9obm5Wbm5ubrnnnt0++23X/D4Q4cO6ZZbbtH8+fP1q1/9ShUVFZo7d64yMzNVWFgoSVq3bp1KSkq0atUqud1urVixQoWFhdqzZ4+GDh16wd/h9/t1+PBhDRo0SBaLJdQmAQAAExiGoaamJmVlZclqvUAfitELkoxXX331vMc89NBDxtVXXx20b+bMmUZhYWHg+4kTJxrFxcWB730+n5GVlWWUlZX1qI6amhpDEhsbGxsbG1sf3Gpqai74WR9yD0uoKisrVVBQELSvsLBQDzzwgCSpvb1dVVVVKi0tDfzcarWqoKBAlZWV3V6zra1NbW1tge+NUy+crqmpUUpKSoRbAAAAosHr9So7O1uDBg264LFRDyx1dXVKT08P2peeni6v16sTJ07o008/lc/n6/aY3bt3d3vNsrIyPfroo2ftT0lJIbAAANDH9GQ4R5+cJVRaWiqPxxPYampqzC4JAABEUdR7WDIyMlRfXx+0r76+XikpKUpKSpLNZpPNZuv2mIyMjG6v6XA45HA4olYzAACIL1HvYcnPz1dFRUXQvs2bNys/P1+SZLfblZeXF3SM3+9XRUVF4BgAAHBxCzmwHD9+XDt37tTOnTslnZy2vHPnTlVXV0s6+bhm9uzZgePnz5+vgwcP6qGHHtLu3bv17LPP6qWXXtLChQsDx5SUlOi5557TCy+8oF27dmnBggVqbm5WUVFRL5sHAAD6g5AfCb399tv6t3/7t8D3JSUlkqQ5c+Zo7dq1qq2tDYQXSRoxYoQ2btyohQsX6qmnntJll12m559/PrAGiyTNnDlTR48e1dKlS1VXV6cJEyaovLz8rIG4AADg4mQxuuYE92Fer1cul0sej4dZQgAA9BGhfH73yVlCAADg4kJgAQAAcY/AAgAA4h6BBQAAxD0CCwAAiHsEFgAAEPeivjQ/AADxxDAMNbV1ytPSoU9b2tV46k/PiQ592twhb2uH/HGy4ofVYpEz0Spngk3ORNvJrxNtZ2xWJZ3xtc0avX4Ii6SctAFRu/6FEFgAAJKkTp9frZ1+tXb4dKLdp7ZOn1o7Tn3f4VNbhz9qH+SGpA6fP/D7Tm+nf39rh1+tnT61dfjU1unv+bUN6USHT42nwknjiQ75/PERSPoSe4JVe5+YZtrvJ7AAwGf4/Sf/Bd79h+bJ79s6T36ot3b41Nrpj6sPwLZTNZ1Z3+kAcrL+oLacaltnHLUhFpISbUpNTlRqsl2pSYm6ZECiXEl2uZISZYuTARM+v9TacXZ4PPO/y9Yzwlw0/zt0JJj7l0JgAWAqv99QU2unGk+c/NevL1r/gjek5rbOoK7/rt/Z2NKuT0/92XiiQ54THYqTJwKmcSRYlWS3nXoUcfIxhCPRJpsler8z0Wbt5jGHTY4zv0+wBvZZ1PNiHAlWpSbbdcmARKUm2ZWanChnoi16jUHEEVgAnFNbp+/Uc/7TH+re1g6F8kaPtk5/IBwExgyc6AgEBc+JDsXrP+ytFsmZaAt8WDpOjSVIsttOjys49aGeYI3iJ3mIHEHjHILHPwS1JdEW1J6un9ltVlnjqD2ARGAB+pWu3grPiY5At/H5HmN0/fx4a+epZ/vt+rT5ZA/Dpy3tamn3xaz2AXabXEmJSohiX3yy3aZLku2nHwMkJ+qS5NP/4k5NtuuS5ES5khOV4kyUI8Eqi4UPbiAeEFiAOHShWQyx7K2wWiRX0ukP+BRnYki9CYk2a2BswCXJiZ8ZM3Dymq6kRDkS6J4HcG4EFiCKDMPQiQ7f6fERLR2fCR9dgaM9+JhezmJIttuCpjp2PR5IOvW9I/Ao4OTjggGOhFNhIrinITXJrkHOBB4PADAdgQXoodYO32cem3SFjNNB43SPx+lw0u7r+fTLz3ImWs94XJEY/DgjKfj7rkcZqUl22U0ezQ8AkUZgwUWnvdN/xuyQM3s1ug8gXeM5WjvCDx6JNktQr8WZAcTVFUSSzhxXwSwGADgTgQX9hmEY+rSlQ7WeE6rztKrO26o6T6tqPV1/ntARb5ua2jrD/h02q0WpSYlnhYygsRldQaRrjEZSopLtNgZvAkAvEFhguq6ZLZ+esQbGifbOoEWRTnR93Xlytc0T7Se/7npMU+c9GUzae7j6paVrIGlSNyEj+XQPSFCvyIBEDXIkEDwAwAQEFkSFYRiq97bpUEOzPjzWrCNNbScfr8RgZkvaQLsyXE5lpDiV4XIq05UU+Do9xalLB9iVkpQoGwNJAaDPILAgbIZh6OjxNn3Q0KIPGpp16FjzyT8bmvXhsRad6AhtDY8BdptST/VyJNtPz3BxnDG7pWsBrCS7TY5TK16mJCUq81RAGZriYHosAPRDBBb0iM9vaN+RJu2sbtQ71Y36V61HHzS06Ph5xoPYrBZddkmSci4doKxUZ9DMFlfyZx69MLMFAHAeBBZ060hTq3ZWN2pnzcmA8u5HjWruZtVTi0UalpqkEWkDlHPpAOWkDdCItGTlXDpA2YOTlRgvbxADAPRpBBZIknbVevXmgWN6p/pTvVPdqI8bT5x1zAC7TeMvS9XnL0/V+MtSdeXQk6GERzAAgGgjsFzkWto79b0/7tbPKz8M2m+xSKOGDtKE7JMBZcLlqbpq6CAGqgIATEFguYhVffip/vOlnfrgWIsk6cbRQ3RdzmBNyE7V+MtcGuRMNLlCAABOIrBchNo7/XqqYq9+vOWA/IaU6XLqB/9vriZflWZ2aQAAdIvAcpHZXedVybp/6P1aryTp9s8P07L/52q5kuhNAQDELwLLRcLnN/T8/xzUD1/bq3afX5ckJ+rJ28Zp2rhMs0sDAOCCCCwXgepjLfrPl3fq7x98Kkkq+NxQPXn7OA0d5DS5MgAAeobA0o8ZhqHfbK/RExvfV0u7TwPsNi2bfrXuuPYy3ocDAOhTCCz91BFvqx767bvasueoJGniiMH64R25yh6cbHJlAACEjsDSD9V6Tuj/+0mlaj45IXuCVQ8VjtY9k0bIyhoqAIA+Kqx101euXKmcnBw5nU653W5t3779nMd2dHToscce0xVXXCGn06nc3FyVl5cHHfPII4/IYrEEbWPGjAmntItew/E23f38NtV8ckKXD07WH745WXNvGElYAQD0aSEHlnXr1qmkpETLli3Tjh07lJubq8LCQh05cqTb4xcvXqyf/OQneuaZZ/T+++9r/vz5uu222/TOO+8EHXf11VertrY2sL3xxhvhtegi1tjSrq8+v00HjzYry+XUr+e5NSp9kNllAQDQaxbDMIxQTnC73bruuuv0ox/9SJLk9/uVnZ2tb37zm1q0aNFZx2dlZenhhx9WcXFxYN9XvvIVJSUl6Ze//KWkkz0sGzZs0M6dO3tUQ1tbm9ra2gLfe71eZWdny+PxKCUlJZTm9BvH2zp19/Pb9I+aRqUNdOil//V/aeSQgWaXBQDAOXm9Xrlcrh59fofUw9Le3q6qqioVFBScvoDVqoKCAlVWVnZ7Tltbm5zO4OmzSUlJZ/Wg7Nu3T1lZWRo5cqTuvvtuVVdXn7OOsrIyuVyuwJadnR1KM/qdE+0+3bP27/pHTaNSkxP1q7luwgoAoF8JKbA0NDTI5/MpPT09aH96errq6uq6PaewsFDLly/Xvn375Pf7tXnzZq1fv161tbWBY9xut9auXavy8nL9+Mc/1qFDh3TDDTeoqamp22uWlpbK4/EEtpqamlCa0a+0dfr0v35Zpe2HPtEgR4J+cY9bozN4DAQA6F+iPkvoqaee0rx58zRmzBhZLBZdccUVKioq0po1awLHTJs2LfD1+PHj5Xa7NXz4cL300ku69957z7qmw+GQw+GIdulxr8Pn1zd//Y7+uveokhJt+lnRdRp3mcvssgAAiLiQeljS0tJks9lUX18ftL++vl4ZGRndnjNkyBBt2LBBzc3N+vDDD7V7924NHDhQI0eOPOfvSU1N1ahRo7R///5Qyruo+PyGHnz5H3rt/XrZE6x6fs61ujZnsNllAQAQFSEFFrvdrry8PFVUVAT2+f1+VVRUKD8//7znOp1ODRs2TJ2dnfrtb3+rGTNmnPPY48eP68CBA8rM5D033TEMQ4s3/FO/23lYCVaLnr3rC5p0JW9aBgD0XyFPay4pKdFzzz2nF154Qbt27dKCBQvU3NysoqIiSdLs2bNVWloaOH7btm1av369Dh48qP/5n//R1KlT5ff79dBDDwWOefDBB7V161Z98MEHevPNN3XbbbfJZrNp1qxZEWhi/2IYhh7/wy79ZnuNrBZpxZ0TVDA2/cInAgDQh4U8hmXmzJk6evSoli5dqrq6Ok2YMEHl5eWBgbjV1dWyWk/noNbWVi1evFgHDx7UwIEDdfPNN+sXv/iFUlNTA8d89NFHmjVrlo4dO6YhQ4Zo8uTJeuuttzRkyJDet7CfWb55r9b87ZAk6b++Ml7/9/gskysCACD6Ql6HJR6FMo+7L3t2y359v3yPJOmxGVdrdn6OuQUBANALUVuHBebZsudIIKwsmjaGsAIAuKgQWPoAwzD0w9f2SpJm5w/X/C9dYXJFAADEFoGlD3h91xH982OPku02PVAwyuxyAACIOQJLnDMMQyteP9m7Muf6HA0eYDe5IgAAYo/AEuc2v1+vfx32aoDdpvtuOPdiewAA9GcEljh2sndlnyTp65NydAm9KwCAixSBJY796V/1er/Wq4GOBM2dTO8KAODiRWCJU36/oacqTvWuXE/vCgDg4kZgiVOvvV+nXV29KzeMMLscAABMRWCJQ37/6bErRZNylJpM7woA4OJGYIlD5f+q0+66Jg1i7AoAAJIILHHH7zf0VFfvyuQRciUnmlwRAADmI7DEmT++V6c99U0a5EzQvZMZuwIAgERgiSsnZwadXNX2nkkj5EqidwUAAInAElc2/rNWe+uPa5AzQffQuwIAQACBJU74zlh3Ze7kkfSuAABwBgJLnPjDu4e1/8hxpTgTVDQ5x+xyAACIKwSWOODzG3q6q3flhpFKcdK7AgDAmQgsceAP7x7WgaPNciUlqmhSjtnlAAAQdwgsJjtz7Mq8G0ZoEL0rAACchcBist//42MdPNqs1OREzbk+x+xyAACISwQWE3X6/HqmYr8kad4NI+ldAQDgHAgsJvr9Pw7rYEOzLqF3BQCA8yKwmOinfz0oSZr3xZEa6EgwuRoAAOIXgcUkPr+h/UeOS5JmTBhmcjUAAMQ3AotJGo63qdNvyGqR0gc5zC4HAIC4RmAxyeHGE5Kk9BSnEmzcBgAAzodPSpPUelolSZkup8mVAAAQ/wgsJunqYclMTTK5EgAA4h+BxSRdPSxZ9LAAAHBBBBaT1HpO9bC46GEBAOBCwgosK1euVE5OjpxOp9xut7Zv337OYzs6OvTYY4/piiuukNPpVG5ursrLy3t1zf7gcOOpHpZUelgAALiQkAPLunXrVFJSomXLlmnHjh3Kzc1VYWGhjhw50u3xixcv1k9+8hM988wzev/99zV//nzddttteuedd8K+Zn9ADwsAAD1nMQzDCOUEt9ut6667Tj/60Y8kSX6/X9nZ2frmN7+pRYsWnXV8VlaWHn74YRUXFwf2feUrX1FSUpJ++ctfhnXNz/J6vXK5XPJ4PEpJSQmlOabo8Pk1avEfZRjS9oenaOggelkAABefUD6/Q+phaW9vV1VVlQoKCk5fwGpVQUGBKisruz2nra1NTmfwB3JSUpLeeOONXl3T6/UGbX1JvbdVhiEl2ixKG8CicQAAXEhIgaWhoUE+n0/p6elB+9PT01VXV9ftOYWFhVq+fLn27dsnv9+vzZs3a/369aqtrQ37mmVlZXK5XIEtOzs7lGaYrmuGUIbLKavVYnI1AADEv6jPEnrqqad01VVXacyYMbLb7frGN76hoqIiWa3h/+rS0lJ5PJ7AVlNTE8GKoy+wBgvjVwAA6JGQUkNaWppsNpvq6+uD9tfX1ysjI6Pbc4YMGaINGzaoublZH374oXbv3q2BAwdq5MiRYV/T4XAoJSUlaOtLWIMFAIDQhBRY7Ha78vLyVFFREdjn9/tVUVGh/Pz8857rdDo1bNgwdXZ26re//a1mzJjR62v2VbWscgsAQEgSQj2hpKREc+bM0bXXXquJEydqxYoVam5uVlFRkSRp9uzZGjZsmMrKyiRJ27Zt08cff6wJEybo448/1iOPPCK/36+HHnqox9fsbw7TwwIAQEhCDiwzZ87U0aNHtXTpUtXV1WnChAkqLy8PDJqtrq4OGp/S2tqqxYsX6+DBgxo4cKBuvvlm/eIXv1BqamqPr9nfsAYLAAChCXkdlnjU19ZhyXt8s441t2vj/56sq7NcZpcDAIAporYOC3qvtcOnY83tkqQselgAAOgRAkuMdc0QciZalZqcaHI1AAD0DQSWGOuaIZTlSpLFwqJxAAD0BIElxgIzhJjSDABAjxFYYiywBgtTmgEA6DECS4x19bCwaBwAAD1HYImxrjVYWDQOAICeI7DEWG0jPSwAAISKwBJjh+lhAQAgZASWGDre1qmm1k5J9LAAABAKAksMdc0QGuRM0EBHyK9xAgDgokVgiaHTb2mmdwUAgFAQWGIosAZLKuNXAAAIBYElhgJrsNDDAgBASAgsMXT6PUL0sAAAEAoCSwzVssotAABhIbDEEGuwAAAQHgJLjBiGwSq3AACEicASI54THTrR4ZPEm5oBAAgVgSVGDp/qXRk8wC5nos3kagAA6FsILDHS9ZZmelcAAAgdgSVGWIMFAIDwEVhiJLAGC6vcAgAQMgJLjNTSwwIAQNgILDFymB4WAADCRmCJEXpYAAAIH4ElBvx+Q3WBwEIPCwAAoSKwxMCx5na1+/yyWKQMAgsAACEjsMRA1xosQwY6lGjjrxwAgFDx6RkDh3mHEAAAvUJgiYFa3tIMAECvEFhigBlCAAD0TliBZeXKlcrJyZHT6ZTb7db27dvPe/yKFSs0evRoJSUlKTs7WwsXLlRra2vg54888ogsFkvQNmbMmHBKi0uswQIAQO8khHrCunXrVFJSolWrVsntdmvFihUqLCzUnj17NHTo0LOO//Wvf61FixZpzZo1uv7667V37159/etfl8Vi0fLlywPHXX311Xr99ddPF5YQcmlxix4WAAB6J+QeluXLl2vevHkqKirS2LFjtWrVKiUnJ2vNmjXdHv/mm29q0qRJuuuuu5STk6ObbrpJs2bNOqtXJiEhQRkZGYEtLS0tvBbFoa73CGXSwwIAQFhCCizt7e2qqqpSQUHB6QtYrSooKFBlZWW351x//fWqqqoKBJSDBw9q06ZNuvnmm4OO27dvn7KysjRy5Ejdfffdqq6uPmcdbW1t8nq9QVu88vkN1Te1SZKy6GEBACAsIT13aWhokM/nU3p6etD+9PR07d69u9tz7rrrLjU0NGjy5MkyDEOdnZ2aP3++vvOd7wSOcbvdWrt2rUaPHq3a2lo9+uijuuGGG/Tee+9p0KBBZ12zrKxMjz76aCilm+ZIU6t8fkMJVouGDHKYXQ4AAH1S1GcJbdmyRU8++aSeffZZ7dixQ+vXr9fGjRv1+OOPB46ZNm2a7rjjDo0fP16FhYXatGmTGhsb9dJLL3V7zdLSUnk8nsBWU1MT7WaErWsNlvQUp2xWi8nVAADQN4XUw5KWliabzab6+vqg/fX19crIyOj2nCVLluhrX/ua5s6dK0kaN26cmpubdd999+nhhx+W1Xp2ZkpNTdWoUaO0f//+bq/pcDjkcPSN3orAGiyMXwEAIGwh9bDY7Xbl5eWpoqIisM/v96uiokL5+fndntPS0nJWKLHZbJIkwzC6Pef48eM6cOCAMjMzQykvLtU2MkMIAIDeCnnucElJiebMmaNrr71WEydO1IoVK9Tc3KyioiJJ0uzZszVs2DCVlZVJkqZPn67ly5fr85//vNxut/bv368lS5Zo+vTpgeDy4IMPavr06Ro+fLgOHz6sZcuWyWazadasWRFsqjkOe5ghBABAb4UcWGbOnKmjR49q6dKlqqur04QJE1ReXh4YiFtdXR3Uo7J48WJZLBYtXrxYH3/8sYYMGaLp06fru9/9buCYjz76SLNmzdKxY8c0ZMgQTZ48WW+99ZaGDBkSgSaaq6uHhRlCAACEz2Kc67lMH+L1euVyueTxeJSSkmJ2OUFm/OgN/eMjj376tTzddHX343wAALgYhfL5zbuEouzwqVVus3hTMwAAYSOwRFF7p18Nx08uGpfJm5oBAAgbgSWK6r2tMgzJkWDV4AF2s8sBAKDPIrBEUddbmjNdTlksLBoHAEC4CCxRxFuaAQCIDAJLFLEGCwAAkUFgiaKuR0KswQIAQO8QWKIosCw/PSwAAPQKgSWKAmuw0MMCAECvEFiiqJYxLAAARASBJUpOtPvU2NIhiVlCAAD0FoElSrpmCA2w25TiDPkdkwAA4AwElig5PeA2iUXjAADoJQJLlATWYOEdQgAA9BqBJUq6eliYIQQAQO8RWKKEGUIAAEQOgSVKWIMFAIDIIbBESW0jPSwAAEQKgSVKeFMzAACRQ2CJAm9rh463dUqSsuhhAQCg1wgsUdA1Q8iVlKhkO4vGAQDQWwSWKGANFgAAIovAEgWBNVhSGb8CAEAkEFiioJYeFgAAIorAEgWH6WEBACCiCCxRQA8LAACRRWCJAtZgAQAgsggsEWYYhg6fWuV2GI+EAACICAJLhH3a0qG2Tr8kKd3lMLkaAAD6BwJLhHX1rqQNdMiRYDO5GgAA+gcCS4R1jV9hSX4AACInrMCycuVK5eTkyOl0yu12a/v27ec9fsWKFRo9erSSkpKUnZ2thQsXqrW1tVfXjFfMEAIAIPJCDizr1q1TSUmJli1bph07dig3N1eFhYU6cuRIt8f/+te/1qJFi7Rs2TLt2rVLq1ev1rp16/Sd73wn7GvGs641WJghBABA5IQcWJYvX6558+apqKhIY8eO1apVq5ScnKw1a9Z0e/ybb76pSZMm6a677lJOTo5uuukmzZo1K6gHJdRrxrOuHhYeCQEAEDkhBZb29nZVVVWpoKDg9AWsVhUUFKiysrLbc66//npVVVUFAsrBgwe1adMm3XzzzWFfs62tTV6vN2iLF7X0sAAAEHEJoRzc0NAgn8+n9PT0oP3p6enavXt3t+fcddddamho0OTJk2UYhjo7OzV//vzAI6FwrllWVqZHH300lNJj5jA9LAAARFzUZwlt2bJFTz75pJ599lnt2LFD69ev18aNG/X444+Hfc3S0lJ5PJ7AVlNTE8GKw+f3G6r30sMCAECkhdTDkpaWJpvNpvr6+qD99fX1ysjI6PacJUuW6Gtf+5rmzp0rSRo3bpyam5t133336eGHHw7rmg6HQw5H/C3K1nC8TR0+Q1aLNHRQ/NUHAEBfFVIPi91uV15enioqKgL7/H6/KioqlJ+f3+05LS0tslqDf43NdnJBNcMwwrpmvDp8ag2W9BSnEmwscQMAQKSE1MMiSSUlJZozZ46uvfZaTZw4UStWrFBzc7OKiookSbNnz9awYcNUVlYmSZo+fbqWL1+uz3/+83K73dq/f7+WLFmi6dOnB4LLha7ZV9Q2sgYLAADREHJgmTlzpo4ePaqlS5eqrq5OEyZMUHl5eWDQbHV1dVCPyuLFi2WxWLR48WJ9/PHHGjJkiKZPn67vfve7Pb5mXxF4SzMvPQQAIKIshmEYZhfRW16vVy6XSx6PRykpKabV8f//aY9+9Jf9mp0/XI/NuMa0OgAA6AtC+fxmoEUEeVs7JEmupESTKwEAoH8hsESQ5wSBBQCAaCCwRFBXYEkhsAAAEFEElgiihwUAgOggsEQQgQUAgOggsESQl8ACAEBUEFgixDAMelgAAIgSAkuEnOjwqcN3ckkbAgsAAJFFYImQrt6VBKtFyXabydUAANC/EFgi5MzHQRaLxeRqAADoXwgsEeJpYfwKAADRQmCJEBaNAwAgeggsEcIMIQAAoofAEiEEFgAAoofAEiEsGgcAQPQQWCKEHhYAAKKHwBIhBBYAAKKHwBIhp2cJJZhcCQAA/Q+BJUK8rZ2S6GEBACAaCCwRwjosAABED4ElQhjDAgBA9BBYIoTAAgBA9BBYIqC1w6f2Tr8kAgsAANFAYImArt4Vm9WigQ5mCQEAEGkElggIDLh1JshisZhcDQAA/Q+BJQIYvwIAQHQRWCLA00JgAQAgmggsEcAaLAAARBeBJQJ4JAQAQHQRWCKAwAIAQHQRWCKAwAIAQHQRWCLAS2ABACCqwgosK1euVE5OjpxOp9xut7Zv337OY2+88UZZLJaztltuuSVwzNe//vWzfj516tRwSjMFPSwAAERXyMuyrlu3TiUlJVq1apXcbrdWrFihwsJC7dmzR0OHDj3r+PXr16u9vT3w/bFjx5Sbm6s77rgj6LipU6fqZz/7WeB7h8MRammmIbAAABBdIfewLF++XPPmzVNRUZHGjh2rVatWKTk5WWvWrOn2+MGDBysjIyOwbd68WcnJyWcFFofDEXTcJZdcEl6LTEBgAQAgukIKLO3t7aqqqlJBQcHpC1itKigoUGVlZY+usXr1at15550aMGBA0P4tW7Zo6NChGj16tBYsWKBjx46d8xptbW3yer1Bm5lYhwUAgOgKKbA0NDTI5/MpPT09aH96errq6uoueP727dv13nvvae7cuUH7p06dqp///OeqqKjQf/3Xf2nr1q2aNm2afD5ft9cpKyuTy+UKbNnZ2aE0I+K8rfSwAAAQTTF9tfDq1as1btw4TZw4MWj/nXfeGfh63LhxGj9+vK644gpt2bJFU6ZMOes6paWlKikpCXzv9XpNCy1tnT61dvgl0cMCAEC0hNTDkpaWJpvNpvr6+qD99fX1ysjIOO+5zc3NevHFF3Xvvfde8PeMHDlSaWlp2r9/f7c/dzgcSklJCdrM0vU4yGKRBjlimv8AALhohBRY7Ha78vLyVFFREdjn9/tVUVGh/Pz885778ssvq62tTV/96lcv+Hs++ugjHTt2TJmZmaGUZ4quNVhSnImyWi0mVwMAQP8U8iyhkpISPffcc3rhhRe0a9cuLViwQM3NzSoqKpIkzZ49W6WlpWedt3r1at1666269NJLg/YfP35c3/rWt/TWW2/pgw8+UEVFhWbMmKErr7xShYWFYTYrdpghBABA9IX8DGPmzJk6evSoli5dqrq6Ok2YMEHl5eWBgbjV1dWyWoNz0J49e/TGG2/otddeO+t6NptN7777rl544QU1NjYqKytLN910kx5//PE+sRYLgQUAgOizGIZhmF1Eb3m9XrlcLnk8npiPZ3n1nY+0cN0/NPnKNP1yrjumvxsAgL4slM9v3iXUS54WelgAAIg2AksveU50SmJKMwAA0URg6SXGsAAAEH0Ell4isAAAEH0Ell4isAAAEH0Ell7yElgAAIg6Aksv0cMCAED0EVh6icACAED0EVh6icACAED0EVh6ob3TrxMdPklSShJvagYAIFoILL3Q1bsiSYOc9LAAABAtBJZe8LaeDCyDnAmyWS0mVwMAQP9FYOkFxq8AABAbBJZeILAAABAbBJZeYNE4AABig8DSC/SwAAAQGwSWXvC0EFgAAIgFAksv0MMCAEBsEFh6oSuwpBBYAACIKgJLL9DDAgBAbBBYeoHAAgBAbBBYeoHAAgBAbBBYeoF1WAAAiA0CSy/QwwIAQGwQWMLU4fOrud0nicACAEC0EVjC1PU4SGJaMwAA0UZgCVPX46BBjgTZrBaTqwEAoH8jsISJReMAAIgdAkuYCCwAAMQOgSVM3tZOSZIrKcHkSgAA6P8ILGFiSjMAALFDYAkTi8YBABA7YQWWlStXKicnR06nU263W9u3bz/nsTfeeKMsFstZ2y233BI4xjAMLV26VJmZmUpKSlJBQYH27dsXTmkxQw8LAACxE3JgWbdunUpKSrRs2TLt2LFDubm5Kiws1JEjR7o9fv369aqtrQ1s7733nmw2m+64447AMd///vf19NNPa9WqVdq2bZsGDBigwsJCtba2ht+yKPO0EFgAAIiVkAPL8uXLNW/ePBUVFWns2LFatWqVkpOTtWbNmm6PHzx4sDIyMgLb5s2blZycHAgshmFoxYoVWrx4sWbMmKHx48fr5z//uQ4fPqwNGzZ0e822tjZ5vd6gLdboYQEAIHZCCizt7e2qqqpSQUHB6QtYrSooKFBlZWWPrrF69WrdeeedGjBggCTp0KFDqqurC7qmy+WS2+0+5zXLysrkcrkCW3Z2dijNiAimNQMAEDshBZaGhgb5fD6lp6cH7U9PT1ddXd0Fz9++fbvee+89zZ07N7Cv67xQrllaWiqPxxPYampqQmlGRNDDAgBA7MR0EZHVq1dr3LhxmjhxYq+u43A45HA4IlRVeAgsAADETkg9LGlpabLZbKqvrw/aX19fr4yMjPOe29zcrBdffFH33ntv0P6u88K5ppmY1gwAQOyEFFjsdrvy8vJUUVER2Of3+1VRUaH8/Pzznvvyyy+rra1NX/3qV4P2jxgxQhkZGUHX9Hq92rZt2wWvaRaf31BTW9dKtwQWAACiLeRHQiUlJZozZ46uvfZaTZw4UStWrFBzc7OKiookSbNnz9awYcNUVlYWdN7q1at166236tJLLw3ab7FY9MADD+iJJ57QVVddpREjRmjJkiXKysrSrbfeGn7Loqird0Vi0C0AALEQcmCZOXOmjh49qqVLl6qurk4TJkxQeXl5YNBsdXW1rNbgjps9e/bojTfe0GuvvdbtNR966CE1NzfrvvvuU2NjoyZPnqzy8nI5nc4wmhR9XeNXBthtSrSxWDAAANFmMQzDMLuI3vJ6vXK5XPJ4PEpJSYn67/tHTaNmrPybslxOvVk6Jeq/DwCA/iiUz2+6B8LAGiwAAMQWgSUMTGkGACC2CCxhoIcFAIDYIrCEgR4WAABii8ASBm8rgQUAgFgisISBVW4BAIgtAksYeCQEAEBsEVjCQGABACC2CCxhILAAABBbBJYwMK0ZAIDYIrCEwdNCDwsAALFEYAmR32+oqa1TEoEFAIBYIbCEqKm1U12viySwAAAQGwSWEHWNX0lKtMmewF8fAACxwCduiJghBABA7BFYQkRgAQAg9ggsISKwAAAQewSWELEGCwAAsUdgCRE9LAAAxB6BJUSne1gSTK4EAICLB4ElRPSwAAAQewSWEHkJLAAAxByBJUTeVgILAACxRmAJEY+EAACIPQJLiAgsAADEHoElRAQWAABij8ASAr/fYNAtAAAmILCE4Hh7p/zGya9Z6RYAgNghsITA03Kyd8WRYJUz0WZyNQAAXDwILCFg/AoAAOYgsISA8SsAAJgjrMCycuVK5eTkyOl0yu12a/v27ec9vrGxUcXFxcrMzJTD4dCoUaO0adOmwM8feeQRWSyWoG3MmDHhlBZV9LAAAGCOkN/gt27dOpWUlGjVqlVyu91asWKFCgsLtWfPHg0dOvSs49vb2/XlL39ZQ4cO1SuvvKJhw4bpww8/VGpqatBxV199tV5//fXThSXE38sFCSwAAJgj5FSwfPlyzZs3T0VFRZKkVatWaePGjVqzZo0WLVp01vFr1qzRJ598ojfffFOJiSc/6HNycs4uJCFBGRkZoZYTUwQWAADMEdIjofb2dlVVVamgoOD0BaxWFRQUqLKysttzfv/73ys/P1/FxcVKT0/XNddcoyeffFI+ny/ouH379ikrK0sjR47U3Xffrerq6nPW0dbWJq/XG7TFQldgYUozAACxFVJgaWhokM/nU3p6etD+9PR01dXVdXvOwYMH9corr8jn82nTpk1asmSJfvjDH+qJJ54IHON2u7V27VqVl5frxz/+sQ4dOqQbbrhBTU1N3V6zrKxMLpcrsGVnZ4fSjLDRwwIAgDmiPlDE7/dr6NCh+ulPfyqbzaa8vDx9/PHH+sEPfqBly5ZJkqZNmxY4fvz48XK73Ro+fLheeukl3XvvvWdds7S0VCUlJYHvvV5vTEILgQUAAHOEFFjS0tJks9lUX18ftL++vv6c408yMzOVmJgom+30Qmuf+9znVFdXp/b2dtnt9rPOSU1N1ahRo7R///5ur+lwOORwOEIpPSJ4JAQAgDlCeiRkt9uVl5enioqKwD6/36+Kigrl5+d3e86kSZO0f/9++f3+wL69e/cqMzOz27AiScePH9eBAweUmZkZSnlRxzosAACYI+R1WEpKSvTcc8/phRde0K5du7RgwQI1NzcHZg3Nnj1bpaWlgeMXLFigTz75RPfff7/27t2rjRs36sknn1RxcXHgmAcffFBbt27VBx98oDfffFO33XabbDabZs2aFYEmRg6PhAAAMEfIY1hmzpypo0ePaunSpaqrq9OECRNUXl4eGIhbXV0tq/V0DsrOztaf/vQnLVy4UOPHj9ewYcN0//3369vf/nbgmI8++kizZs3SsWPHNGTIEE2ePFlvvfWWhgwZEoEmRo63tVMSgQUAgFizGIZhmF1Eb3m9XrlcLnk8HqWkpETldxiGoSsf/qN8fkNvlU5RhssZld8DAMDFIpTPb94l1EPN7T75/CezHT0sAADEFoGlh7rGr9htVjkT+WsDACCW+OTtIU/L6SnNFovF5GoAALi4EFh66PQMofh7KSMAAP0dgaWHmNIMAIB5CCw9xKJxAACYh8DSQ/SwAABgHgJLDxFYAAAwD4GlhwgsAACYh8DSQ7ypGQAA8xBYeogeFgAAzENg6SECCwAA5iGw9JCXR0IAAJiGwNJD9LAAAGAeAksPGIZBYAEAwEQElh5oafep029IIrAAAGAGAksPeFtP9q4kWC1KtttMrgYAgIsPgaUHznwcZLFYTK4GAICLD4GlBzwtjF8BAMBMBJYeYJVbAADMRWDpAWYIAQBgLgJLDxBYAAAwF4GlB7wEFgAATEVg6QF6WAAAMBeBpQcILAAAmIvA0gMEFgAAzEVg6QGmNQMAYC4CSw/QwwIAgLkILD3gOdEpicACAIBZCCwXYBjG6WnNyQQWAADMQGC5gNYOv9p9fklSijPB5GoAALg4EVguoGv8is1q0UAHgQUAADOEFVhWrlypnJwcOZ1Oud1ubd++/bzHNzY2qri4WJmZmXI4HBo1apQ2bdrUq2vGSmCGkDNBFovF5GoAALg4hRxY1q1bp5KSEi1btkw7duxQbm6uCgsLdeTIkW6Pb29v15e//GV98MEHeuWVV7Rnzx4999xzGjZsWNjXjCVmCAEAYL6QA8vy5cs1b948FRUVaezYsVq1apWSk5O1Zs2abo9fs2aNPvnkE23YsEGTJk1STk6OvvSlLyk3Nzfsa8YS7xECAMB8IQWW9vZ2VVVVqaCg4PQFrFYVFBSosrKy23N+//vfKz8/X8XFxUpPT9c111yjJ598Uj6fL+xrtrW1yev1Bm3RwqJxAACYL6TA0tDQIJ/Pp/T09KD96enpqqur6/acgwcP6pVXXpHP59OmTZu0ZMkS/fCHP9QTTzwR9jXLysrkcrkCW3Z2dijNCAmPhAAAMF/UZwn5/X4NHTpUP/3pT5WXl6eZM2fq4Ycf1qpVq8K+ZmlpqTweT2CrqamJYMXBCCwAAJgvpHm6aWlpstlsqq+vD9pfX1+vjIyMbs/JzMxUYmKibDZbYN/nPvc51dXVqb29PaxrOhwOORyOUEoPG4EFAADzhdTDYrfblZeXp4qKisA+v9+viooK5efnd3vOpEmTtH//fvn9/sC+vXv3KjMzU3a7PaxrxhKDbgEAMF/Ij4RKSkr03HPP6YUXXtCuXbu0YMECNTc3q6ioSJI0e/ZslZaWBo5fsGCBPvnkE91///3au3evNm7cqCeffFLFxcU9vqaZ6GEBAMB8IS/dOnPmTB09elRLly5VXV2dJkyYoPLy8sCg2erqalmtp3NQdna2/vSnP2nhwoUaP368hg0bpvvvv1/f/va3e3xNMxFYAAAwn8UwDMPsInrL6/XK5XLJ4/EoJSUlotf+8vKt2nfkuH49163rr0yL6LUBALiYhfL5zbuELoB1WAAAMB+B5QJ4JAQAgPkILOfR2uFTW+fJ2U2uZAILAABmCXnQ7cWm5Muj5DnRoYF2/qoAADALn8Ln4Uy06X9PucrsMgAAuOjxSAgAAMQ9AgsAAIh7BBYAABD3CCwAACDuEVgAAEDcI7AAAIC4R2ABAABxj8ACAADiHoEFAADEPQILAACIewQWAAAQ9wgsAAAg7hFYAABA3OsXb2s2DEOS5PV6Ta4EAAD0VNfndtfn+Pn0i8DS1NQkScrOzja5EgAAEKqmpia5XK7zHmMxehJr4pzf79fhw4c1aNAgWSyWiF7b6/UqOztbNTU1SklJiei14wnt7D8uhjZKtLO/oZ39RyhtNAxDTU1NysrKktV6/lEq/aKHxWq16rLLLovq70hJSem3/3GdiXb2HxdDGyXa2d/Qzv6jp228UM9KFwbdAgCAuEdgAQAAcY/AcgEOh0PLli2Tw+Ewu5Soop39x8XQRol29je0s/+IVhv7xaBbAADQv9HDAgAA4h6BBQAAxD0CCwAAiHsEFgAAEPcILAAAIO4RWC5g5cqVysnJkdPplNvt1vbt280uKaIeeeQRWSyWoG3MmDFml9Urf/3rXzV9+nRlZWXJYrFow4YNQT83DENLly5VZmamkpKSVFBQoH379plTbC9cqJ1f//rXz7q3U6dONafYXigrK9N1112nQYMGaejQobr11lu1Z8+eoGNaW1tVXFysSy+9VAMHDtRXvvIV1dfXm1Rx6HrSxhtvvPGs+zl//nyTKg7Pj3/8Y40fPz6wAmp+fr7++Mc/Bn7e1+9jlwu1sz/cy8/63ve+J4vFogceeCCwL9L3k8ByHuvWrVNJSYmWLVumHTt2KDc3V4WFhTpy5IjZpUXU1Vdfrdra2sD2xhtvmF1SrzQ3Nys3N1crV67s9uff//739fTTT2vVqlXatm2bBgwYoMLCQrW2tsa40t65UDslaerUqUH39je/+U0MK4yMrVu3qri4WG+99ZY2b96sjo4O3XTTTWpubg4cs3DhQv33f/+3Xn75ZW3dulWHDx/W7bffbmLVoelJGyVp3rx5Qffz+9//vkkVh+eyyy7T9773PVVVVentt9/Wv//7v2vGjBn617/+Janv38cuF2qn1Pfv5Zn+/ve/6yc/+YnGjx8ftD/i99PAOU2cONEoLi4OfO/z+YysrCyjrKzMxKoia9myZUZubq7ZZUSNJOPVV18NfO/3+42MjAzjBz/4QWBfY2Oj4XA4jN/85jcmVBgZn22nYRjGnDlzjBkzZphSTzQdOXLEkGRs3brVMIyT9y8xMdF4+eWXA8fs2rXLkGRUVlaaVWavfLaNhmEYX/rSl4z777/fvKKi5JJLLjGef/75fnkfz9TVTsPoX/eyqanJuOqqq4zNmzcHtSsa95MelnNob29XVVWVCgoKAvusVqsKCgpUWVlpYmWRt2/fPmVlZWnkyJG6++67VV1dbXZJUXPo0CHV1dUF3VeXyyW3293v7qskbdmyRUOHDtXo0aO1YMECHTt2zOySes3j8UiSBg8eLEmqqqpSR0dH0D0dM2aMLr/88j57Tz/bxi6/+tWvlJaWpmuuuUalpaVqaWkxo7yI8Pl8evHFF9Xc3Kz8/Px+eR+ls9vZpb/cy+LiYt1yyy1B902Kzv+X/eJtzdHQ0NAgn8+n9PT0oP3p6enavXu3SVVFntvt1tq1azV69GjV1tbq0Ucf1Q033KD33ntPgwYNMru8iKurq5Okbu9r18/6i6lTp+r222/XiBEjdODAAX3nO9/RtGnTVFlZKZvNZnZ5YfH7/XrggQc0adIkXXPNNZJO3lO73a7U1NSgY/vqPe2ujZJ01113afjw4crKytK7776rb3/729qzZ4/Wr19vYrWh++c//6n8/Hy1trZq4MCBevXVVzV27Fjt3LmzX93Hc7VT6j/38sUXX9SOHTv097///ayfReP/SwLLRW7atGmBr8ePHy+3263hw4frpZde0r333mtiZeitO++8M/D1uHHjNH78eF1xxRXasmWLpkyZYmJl4SsuLtZ7773X58dZnc+52njfffcFvh43bpwyMzM1ZcoUHThwQFdccUWsywzb6NGjtXPnTnk8Hr3yyiuaM2eOtm7danZZEXeudo4dO7Zf3Muamhrdf//92rx5s5xOZ0x+J4+EziEtLU02m+2sEc319fXKyMgwqaroS01N1ahRo7R//36zS4mKrnt3sd1XSRo5cqTS0tL67L39xje+oT/84Q/6y1/+ossuuyywPyMjQ+3t7WpsbAw6vi/e03O1sTtut1uS+tz9tNvtuvLKK5WXl6eysjLl5ubqqaee6lf3UTp3O7vTF+9lVVWVjhw5oi984QtKSEhQQkKCtm7dqqeffloJCQlKT0+P+P0ksJyD3W5XXl6eKioqAvv8fr8qKiqCnkP2N8ePH9eBAweUmZlpdilRMWLECGVkZATdV6/Xq23btvXr+ypJH330kY4dO9bn7q1hGPrGN76hV199VX/+8581YsSIoJ/n5eUpMTEx6J7u2bNH1dXVfeaeXqiN3dm5c6ck9bn7+Vl+v19tbW394j6eT1c7u9MX7+WUKVP0z3/+Uzt37gxs1157re6+++7A1xG/n70fI9x/vfjii4bD4TDWrl1rvP/++8Z9991npKamGnV1dWaXFjH/+Z//aWzZssU4dOiQ8be//c0oKCgw0tLSjCNHjphdWtiampqMd955x3jnnXcMScby5cuNd955x/jwww8NwzCM733ve0Zqaqrxu9/9znj33XeNGTNmGCNGjDBOnDhhcuWhOV87m5qajAcffNCorKw0Dh06ZLz++uvGF77wBeOqq64yWltbzS49JAsWLDBcLpexZcsWo7a2NrC1tLQEjpk/f75x+eWXG3/+85+Nt99+28jPzzfy8/NNrDo0F2rj/v37jccee8x4++23jUOHDhm/+93vjJEjRxpf/OIXTa48NIsWLTK2bt1qHDp0yHj33XeNRYsWGRaLxXjttdcMw+j797HL+drZX+5ldz47+ynS95PAcgHPPPOMcfnllxt2u92YOHGi8dZbb5ldUkTNnDnTyMzMNOx2uzFs2DBj5syZxv79+80uq1f+8pe/GJLO2ubMmWMYxsmpzUuWLDHS09MNh8NhTJkyxdizZ4+5RYfhfO1saWkxbrrpJmPIkCFGYmKiMXz4cGPevHl9Mmx310ZJxs9+9rPAMSdOnDD+4z/+w7jkkkuM5ORk47bbbjNqa2vNKzpEF2pjdXW18cUvftEYPHiw4XA4jCuvvNL41re+ZXg8HnMLD9E999xjDB8+3LDb7caQIUOMKVOmBMKKYfT9+9jlfO3sL/eyO58NLJG+nxbDMIzw+mYAAABigzEsAAAg7hFYAABA3COwAACAuEdgAQAAcY/AAgAA4h6BBQAAxD0CCwAAiHsEFgAAEPcILAAAIO4RWAAAQNwjsAAAgLj3fwC0VoCzTRnEPwAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"markdown","source":"We can view the final accuracy of the model that was just trained.","metadata":{}},{"cell_type":"code","source":"learn.recorder.values[-1][2]","metadata":{"execution":{"iopub.status.busy":"2024-02-18T03:08:44.816754Z","iopub.execute_input":"2024-02-18T03:08:44.818229Z","iopub.status.idle":"2024-02-18T03:08:44.826746Z","shell.execute_reply.started":"2024-02-18T03:08:44.818186Z","shell.execute_reply":"2024-02-18T03:08:44.825142Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"0.98233562707901"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}